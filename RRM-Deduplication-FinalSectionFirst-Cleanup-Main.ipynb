{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis\n",
      "Archive\n",
      "DataAndDuplicateReport_110822.xlsx\n",
      "\n",
      "DataAndDuplicateReport_110822.xlsx\n",
      "DataAndDuplicateReport_110922.xlsx\n",
      "\n",
      "DataAndDuplicateReport_110922.xlsx\n",
      "Temp\n",
      "\n",
      "documents available for processing\n",
      "\n",
      "['DataAndDuplicateReport_110822.xlsx', 'DataAndDuplicateReport_110922.xlsx']\n",
      "Analysis\n",
      "Archive\n",
      "DataAndDuplicateReport_110922.xlsx\n",
      "incorrect file name is present.\n",
      "DataAndDuplicateReport_2022-12-30_13-48-41.csv\n",
      "\n",
      "DataAndDuplicateReport_2022-12-30_13-48-41.csv\n",
      "Temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-d67b2ab4730a>:150: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  df1.loc[(pd.to_datetime(df1['ExpiryDate']) != '1990-01-01') & (pd.to_datetime(date.today()) >= df1['ExpiryDate']), 'ExpiryDate_status'] += ' & Expired'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis\n",
      "Archive\n",
      "DataAndDuplicateReport_110922.xlsx\n",
      "incorrect file name is present.\n",
      "DDRProcessed_2022-12-30_13-52-13.csv\n",
      "\n",
      "DDRProcessed_2022-12-30_13-52-13.csv\n",
      "Temp\n",
      "\n",
      "\n",
      "Duration: 0:00:46.084849\n",
      "Analysiss until next document is processedd\n",
      "Archive\n",
      "DataAndDuplicateReport_2022-12-30_13-53-11.csv\n",
      "\n",
      "DataAndDuplicateReport_2022-12-30_13-53-11.csv\n",
      "Temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-d67b2ab4730a>:150: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  df1.loc[(pd.to_datetime(df1['ExpiryDate']) != '1990-01-01') & (pd.to_datetime(date.today()) >= df1['ExpiryDate']), 'ExpiryDate_status'] += ' & Expired'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis\n",
      "Archive\n",
      "DDRProcessed_2022-12-30_13-56-19.csv\n",
      "\n",
      "DDRProcessed_2022-12-30_13-56-19.csv\n",
      "Temp\n",
      "\n",
      "\n",
      "Duration: 0:00:47.660962\n",
      "[Errno 2] No such file or directory: 'DataAndDuplicateReportAutomation/DDRProcessed_2022-12-30_13-56-19.csv'\n",
      "All errors identified.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from glob import glob\n",
    "import shutil\n",
    "import requests\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import ctypes\n",
    "import threading\n",
    "\n",
    "global processlist, df\n",
    "conn = False\n",
    "con = None\n",
    "\n",
    "filepath = r'DataAndDuplicateReportAutomation'\n",
    "try:\n",
    "    \n",
    "    logging.basicConfig(filename = 'RRMDuplicateExceptionsFinalSection.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "    logging.info(f'\\nLOG START: {datetime.now()}\\n')\n",
    "    \n",
    "\n",
    "\n",
    "    def check_files():\n",
    "        global processlist\n",
    "        processlist = []\n",
    "        for file in os.listdir(filepath):\n",
    "            print(f'{file}')\n",
    "            if file.startswith(\"DataAndDuplicateReport\"):\n",
    "                print(f'\\n{file}')\n",
    "                processlist += [file]\n",
    "            elif file.startswith((\"Archive\",\"Analysis\",\"Temp\")):\n",
    "                pass\n",
    "            elif ~file.startswith(\"DataAndDuplicateReport\"):\n",
    "                print('incorrect file name is present.')\n",
    "        if processlist == []:\n",
    "            print('No files were present or did not have the correct naming scheme.')\n",
    "            processlist += ['None']\n",
    "        else:\n",
    "            pass\n",
    "        return processlist\n",
    "    \n",
    "    def convert_to_CSV(doc):\n",
    "        #global df\n",
    "        pd.read_excel(f'{filepath}'+'/'+f'{doc}', sheet_name='Daily data report').to_csv(f'{filepath}'+'/'+'DataAndDuplicateReport' + '_' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '.csv', encoding = 'utf-8', index = False)\n",
    "        shutil.move(f'{filepath}'+'/'+f'{doc}', 'DataAndDuplicateReportAutomation/Archive/xlsx/'+f'{doc}')\n",
    "        #for f in glob('DataAndDuplicateReportAutomation/DataAndDuplicateReport*.csv'):\n",
    "            #df = pd.read_csv(f)\n",
    "        #display(df)\n",
    "        return #df\n",
    "    \n",
    "    def process_CSV():\n",
    "        global processlist, df\n",
    "        processlist = []\n",
    "        for file in os.listdir(filepath):\n",
    "            print(f'{file}')\n",
    "            if file.startswith(\"DataAndDuplicateReport\") and file.endswith(\".csv\"):\n",
    "                print(f'\\n{file}')\n",
    "                processlist += [file]\n",
    "            elif file.startswith((\"Archive\",\"Analysis\",\"Temp\")):\n",
    "                pass\n",
    "            elif ~file.startswith(\"DataAndDuplicateReport\"):\n",
    "                print('incorrect file name is present.')\n",
    "        if processlist == []:\n",
    "            print('No files were present or did not have the correct naming scheme.')\n",
    "            processlist += ['None']\n",
    "        else:\n",
    "            pass\n",
    "        return processlist\n",
    "    \n",
    "    def move_processed():\n",
    "        global processedlist\n",
    "        processedlist = []\n",
    "        for file in os.listdir(filepath):\n",
    "            print(f'{file}')\n",
    "            if file.startswith(\"DDRProcessed\") and file.endswith(\".csv\"):\n",
    "                print(f'\\n{file}')\n",
    "                processedlist += [file]\n",
    "            elif file.startswith((\"Archive\",\"Analysis\",\"Temp\")):\n",
    "                pass\n",
    "            elif ~file.startswith(\"DDRProcessed\"):\n",
    "                print('incorrect file name is present.')\n",
    "        if processedlist == []:\n",
    "            print('No files were present or did not have the correct naming scheme.')\n",
    "            processedlist += ['None']\n",
    "        else:\n",
    "            pass\n",
    "        return processedlist\n",
    "\n",
    "    def duplication_extraction():\n",
    "    \n",
    "        global df1pre, df1, df2, df3_nofilter\n",
    "        \n",
    "        pd.set_option('display.max_columns', None)\n",
    "    \n",
    "        df1pre = pd.read_csv(f'DataAndDuplicateReportAutomation/{processlist[0]}')\n",
    "        \n",
    "        df1 = df1pre.sort_values(by=['PersonPartyID','CreatedDatetime'], ascending = True)\n",
    "\n",
    "        today = date.today()\n",
    "        first = today.replace(day=1)\n",
    "        last_month = first - timedelta(days=1)\n",
    "        tenth_of_current_month = today.replace(day=10)\n",
    "        first_of_previous_month = last_month.replace(day=1)\n",
    "        next_month = today.replace(day=28) + timedelta(days=4)\n",
    "        next_month = next_month - timedelta(days=next_month.day)\n",
    "\n",
    "        df1['CreatedDatetime']= pd.to_datetime(df1['CreatedDatetime']).dt.date\n",
    "        df1['EffectiveDate'] = pd.to_datetime(df1['EffectiveDate']).dt.date\n",
    "        df1.loc[(df1['ExpiryDate'].isna()), 'ExpiryDate'] = '1/1/1990'\n",
    "        df1['ExpiryDate'] = pd.to_datetime(df1['ExpiryDate']).dt.date\n",
    "        df1['LastModifiedDatetime'] = pd.to_datetime(df1['LastModifiedDatetime']).dt.date\n",
    "\n",
    "        df1 = df1.where(pd.notnull(df1), None)\n",
    "\n",
    "        df1.loc[~(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['CreatedDatetime'].transform(max) == df1['CreatedDatetime']), 'CreatedDatetime_status'] = 'Previous'\n",
    "        df1.loc[(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['CreatedDatetime'].transform(max) == df1['CreatedDatetime']), 'CreatedDatetime_status'] = 'Latest'\n",
    "\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) == df1['ExpiryDate']) & ~(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(min) == df1['ExpiryDate']), 'ExpiryDate_status'] = 'Latest'\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & ((df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) == df1['ExpiryDate']) & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(min) == df1['ExpiryDate'])), 'ExpiryDate_status'] = 'Current'\n",
    "        df1.loc[~(df1['CreatedDatetime_status'] == 'Latest') & ((df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) == df1['ExpiryDate']) & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(min) == df1['ExpiryDate'])), 'ExpiryDate_status'] = 'Previous CD but Max & Min Exp Date Error'\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) != df1['ExpiryDate']), 'ExpiryDate_status'] = 'Latest CD but not Max Exp Date Error'\n",
    "        df1.loc[~(df1['CreatedDatetime_status'] == 'Latest') & ((df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) == df1['ExpiryDate']) & ~(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(min) == df1['ExpiryDate'])), 'ExpiryDate_status'] = 'Previous CD but Max & not Min Exp Date Error'\n",
    "        df1.loc[~(df1['CreatedDatetime_status'] == 'Latest') & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['ExpiryDate'].transform(max) != df1['ExpiryDate']), 'ExpiryDate_status'] = 'Previous CD and not Max Exp Date Error'\n",
    "        df1.loc[pd.to_datetime(df1['ExpiryDate']) == '1990-01-01', 'ExpiryDate_status'] += ' & Null Placeholder'\n",
    "        df1.loc[(pd.to_datetime(df1['ExpiryDate']) != '1990-01-01') & (pd.to_datetime(date.today()) >= df1['ExpiryDate']), 'ExpiryDate_status'] += ' & Expired'\n",
    "\n",
    "        df1.loc[~(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['EffectiveDate'].transform(max) == df1['EffectiveDate']), 'EffectiveDate_status'] = 'Previous EffectiveDate'\n",
    "        df1.loc[(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['EffectiveDate'].transform(max) == df1['EffectiveDate']), 'EffectiveDate_status'] = 'Current EffectiveDate'\n",
    "        df1.loc[(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['EffectiveDate'].transform(max) == df1['EffectiveDate']) & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['LastModifiedDatetime'].transform(max) == df1['LastModifiedDatetime']), 'EffectiveDate_status'] += ' & Latest MD'\n",
    "        df1.loc[(df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['EffectiveDate'].transform(max) == df1['EffectiveDate']) & (df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['LastModifiedDatetime'].transform(max) != df1['LastModifiedDatetime']), 'EffectiveDate_status'] += ' & Previous MD'\n",
    "        \n",
    "        df1.loc[(df1['EffectiveDate']) < (df1['CreatedDatetime']), 'EffectiveDate_status'] += ' & Eff Date less than CD Anomaly'\n",
    "        df1.loc[(((df1['EffectiveDate']) >= (df1['ExpiryDate'])) & ~(pd.to_datetime(df1['ExpiryDate']) == '1990-01-01')), 'EffectiveDate_status'] += ' & Eff Date greater than/Equal to Exp Date Error'\n",
    "\n",
    "        todayv2 = datetime.strptime(str(today), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "        todayv3 = datetime.strptime(str(today), '%Y-%m-%d').strftime('%m-%d')\n",
    "        last_monthv2 = datetime.strptime(str(last_month), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "        df1['ExpiryDateFirstOfPreviousMonthStr'] = ((df1['ExpiryDate']) - relativedelta(months=1)).astype('str')\n",
    "        df1['ExpiryDateMaxEffDateMinus1'] = df1.groupby(['PersonPartyID','LegalEntityPartyID','rateType','RateBasis'])['EffectiveDate'].transform(max)\n",
    "        df1['ExpiryDateMaxEffDateMinus1'] = ((df1['ExpiryDateMaxEffDateMinus1']) - relativedelta(days=1)).astype('str')\n",
    "        df1['Update_Statement'] = 'update resourcepersonrate set'\n",
    "        df1.loc[df1['ExpiryDate_status'].str.contains('Expired') , 'Update_Statement'] += \" expirydate = '1990-01-01'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & not Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate & Eff Date less than CD Anomaly'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Previous MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Previous MD & Eff Date less than CD Anomaly'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD & Eff Date less than CD Anomaly'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD & Eff Date less than CD Anomaly'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD and not Max Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD & Eff Date less than CD Anomaly'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD and not Max Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Previous MD & Eff Date greater than/Equal to Exp Date Error'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD and not Max Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & not Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & not Min Exp Date Error') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Previous MD'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD and not Max Exp Date Error') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate'), 'Update_Statement'] += f\" expirydate = '\"+df1['ExpiryDateMaxEffDateMinus1']+\"'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & (df1['ExpiryDate_status'] == 'Current & Null Placeholder') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate & Eff Date less than CD Anomaly') & df1['InternalpersonCategoryname'].str.contains('Practice Support'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & (df1['ExpiryDate_status'] == 'Current & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Previous MD & Eff Date less than CD Anomaly') & df1['InternalpersonCategoryname'].str.contains('Practice Support'), 'Update_Statement'] += f\" expirydate = '\"+df1['ExpiryDateMaxEffDateMinus1']+\"'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Latest') & (df1['ExpiryDate_status'] == 'Current & Null Placeholder') & (df1['EffectiveDate_status'] == 'Previous EffectiveDate'), 'Update_Statement'] += f\" expirydate = '{last_monthv2}'\"\n",
    "        df1.loc[(df1['CreatedDatetime_status'] == 'Previous') & (df1['ExpiryDate_status'] == 'Previous CD but Max & Min Exp Date Error & Null Placeholder') & (df1['EffectiveDate_status'] == 'Current EffectiveDate & Latest MD') & df1['ResourceRole'].str.contains('Specialist'), 'Update_Statement'] = ''\n",
    "        df1.loc[df1['Update_Statement'] == 'update resourcepersonrate set' , 'Update_Statement'] = ''\n",
    "        df1.loc[df1['Update_Statement'] != '' , 'Update_Statement'] += f\", lastmodifieddatetime = '{todayv2}'\"\n",
    "        df1.loc[df1['Update_Statement'] != '' , 'Update_Statement'] += f\", comments = comments +' | edit from {todayv3} correction automation'\"\n",
    "        df1.loc[df1['Update_Statement'] != '' , 'Update_Statement'] += f\" where resourcepersonratesk = '\"+df1['Resourcepersonratesk'].astype('str')+\"'\"\n",
    "\n",
    "        df2 = df1[['PersonPartyID','LegalEntityPartyID','rateType','EffectiveDate','ExpiryDate','CreatedDatetime','LastModifiedDatetime','RateBasis','CreatedDatetime_status','ExpiryDate_status','EffectiveDate_status','Update_Statement']]\n",
    "        shutil.move(f'{filepath}'+'/'+f'{processlist[0]}', 'DataAndDuplicateReportAutomation/Temp/'+f'{processlist[0]}')\n",
    "        df2.to_csv(f'{filepath}'+'/'+'DDRProcessed' + '_' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '.csv', encoding = 'utf-8', index = False)\n",
    "        #display(df2)\n",
    "\n",
    "        return\n",
    "\n",
    "    check_files()\n",
    "    if 'None' not in processlist:\n",
    "        print('\\ndocuments available for processing\\n')\n",
    "        print(processlist)\n",
    "        for doc in enumerate(processlist):\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                convert_to_CSV(doc[1])\n",
    "                gend_time = datetime.now()\n",
    "                process_CSV()\n",
    "                duplication_extraction()\n",
    "                move_processed()\n",
    "                print(\"\")\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "            except Exception as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "            for i in range(10, -1, -1):\n",
    "                    print(f\"{i} seconds until next document is processed\", end = \"\\r\")\n",
    "                    ti.sleep(1)\n",
    "    else:\n",
    "        print('documents not available for processing')\n",
    "        pass\n",
    "    \n",
    "    if 'None' not in processedlist:\n",
    "        for file in processedlist:\n",
    "            shutil.move(f'{filepath}'+'/'+f'{processedlist[0]}', 'DataAndDuplicateReportAutomation/Archive/csv/'+f'{processedlist[0]}')\n",
    "            move_processed()\n",
    "        print('Processing Complete')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        logging.exception(\"message\")\n",
    "        pass\n",
    "    \n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "        \n",
    "finally:\n",
    "    logging.info(f'\\nLOG END: {datetime.now()}\\n')\n",
    "    print(\"All errors identified.\")\n",
    "    if conn == True:\n",
    "        close_connection()\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd==2.0.1Note: you may need to restart the kernel to use updated packages.\n",
      "  Using cached xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 1.2.0\n",
      "    Uninstalling xlrd-1.2.0:\n",
      "      Successfully uninstalled xlrd-1.2.0\n",
      "Successfully installed xlrd-2.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
