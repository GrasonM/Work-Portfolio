{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n",
      "Connection established to: Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n",
      "[('CommonConfig', 'dbo', 'Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised_stage', 'BASE TABLE')]\n",
      "Current backup for Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised_stage exists.\n",
      "6605 Existing records\n",
      "Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised_stage has been succesfully truncated to import new data.\n",
      "\n",
      "Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised has been updated with 6605 records\n",
      "\n",
      "# of records in each table:  6605 6605\n",
      "Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised_stage-backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.318185\n",
      "\n",
      "\n",
      "Duration: 0:00:11.097866\n",
      "\n",
      "[('CommonConfig', 'dbo', 'ORD-CostCenter_stage', 'BASE TABLE')]\n",
      "ORD-CostCenter_stage-backup does not exist in the database and will need to be created once parent table has data\n",
      "\n",
      "Backup Duration: 0:00:00.459765\n",
      "\n",
      "0 Existing records\n",
      "ORD-CostCenter has been updated with 42430 records\n",
      "\n",
      "Duration: 0:00:51.815885\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-JobLevel-en', 'BASE TABLE')]\n",
      "Current backup for NS-JobLevel-en exists.\n",
      "23 Existing records\n",
      "NS-JobLevel-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-JobLevel-en has been updated with 23 records\n",
      "\n",
      "# of records in each table:  23 23\n",
      "NS-JobLevel-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.264257\n",
      "\n",
      "\n",
      "Duration: 0:00:08.182171\n",
      "\n",
      "[('CommonConfig', 'dbo', 'LEL-PwCLegalEntity-en', 'BASE TABLE')]\n",
      "Current backup for LEL-PwCLegalEntity-en exists.\n",
      "1510 Existing records\n",
      "LEL-PwCLegalEntity-en has been succesfully truncated to import new data.\n",
      "\n",
      "LEL-PwCLegalEntity-en has been updated with 1510 records\n",
      "\n",
      "# of records in each table:  1510 1510\n",
      "LEL-PwCLegalEntity-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.282240\n",
      "\n",
      "\n",
      "Duration: 0:01:00.534072\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-ManagementLevel-en', 'BASE TABLE')]\n",
      "Current backup for NS-ManagementLevel-en exists.\n",
      "11 Existing records\n",
      "NS-ManagementLevel-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ManagementLevel-en has been updated with 11 records\n",
      "\n",
      "# of records in each table:  11 11\n",
      "NS-ManagementLevel-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.264328\n",
      "\n",
      "\n",
      "Duration: 0:00:05.726280\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-PwCNetworkNode-en', 'BASE TABLE')]\n",
      "Current backup for NS-PwCNetworkNode-en exists.\n",
      "458 Existing records\n",
      "NS-PwCNetworkNode-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-PwCNetworkNode-en has been updated with 458 records\n",
      "\n",
      "# of records in each table:  458 458\n",
      "NS-PwCNetworkNode-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.273269\n",
      "\n",
      "\n",
      "Duration: 0:00:26.140014\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-PwCNetworkNode-en-Territory', 'BASE TABLE')]\n",
      "Current backup for NS-PwCNetworkNode-en-Territory exists.\n",
      "113 Existing records\n",
      "NS-PwCNetworkNode-en-Territory has been succesfully truncated to import new data.\n",
      "\n",
      "NS-PwCNetworkNode-en-Territory has been updated with 113 records\n",
      "\n",
      "# of records in each table:  113 113\n",
      "NS-PwCNetworkNode-en-Territory_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.260341\n",
      "\n",
      "\n",
      "Duration: 0:00:11.059244\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-ResourceRole-en', 'BASE TABLE')]\n",
      "Current backup for NS-ResourceRole-en exists.\n",
      "14 Existing records\n",
      "NS-ResourceRole-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ResourceRole-en has been updated with 14 records\n",
      "\n",
      "# of records in each table:  14 14\n",
      "NS-ResourceRole-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.261301\n",
      "\n",
      "\n",
      "Duration: 0:00:05.628379\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-ResourceType-en', 'BASE TABLE')]\n",
      "Current backup for NS-ResourceType-en exists.\n",
      "2 Existing records\n",
      "NS-ResourceType-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ResourceType-en has been updated with 2 records\n",
      "\n",
      "# of records in each table:  2 2\n",
      "NS-ResourceType-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.260303\n",
      "\n",
      "\n",
      "Duration: 0:00:05.713285\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-WorkerType-en', 'BASE TABLE')]\n",
      "Current backup for NS-WorkerType-en exists.\n",
      "2 Existing records\n",
      "NS-WorkerType-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-WorkerType-en has been updated with 2 records\n",
      "\n",
      "# of records in each table:  2 2\n",
      "NS-WorkerType-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.279220\n",
      "\n",
      "\n",
      "Duration: 0:00:04.835155\n",
      "\n",
      "[('CommonConfig', 'dbo', 'NS-WorkerType-en_NS-ContractType-en_Normalised', 'BASE TABLE')]\n",
      "Current backup for NS-WorkerType-en_NS-ContractType-en_Normalised exists.\n",
      "12 Existing records\n",
      "NS-WorkerType-en_NS-ContractType-en_Normalised has been succesfully truncated to import new data.\n",
      "\n",
      "NS-WorkerType-en_NS-ContractType-en_Normalised has been updated with 12 records\n",
      "\n",
      "# of records in each table:  12 12\n",
      "NS-WorkerType-en_NS-ContractType-en_Normalised_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.326166\n",
      "\n",
      "\n",
      "Duration: 0:00:05.501732\n",
      "\n",
      "[('CommonConfig', 'dbo', 'ORD-CostCenter', 'BASE TABLE')]\n",
      "Current backup for ORD-CostCenter exists.\n",
      "64861 Existing records\n",
      "ORD-CostCenter has been succesfully truncated to import new data.\n",
      "\n",
      "ORD-CostCenter has been updated with 64861 records\n",
      "\n",
      "# of records in each table:  64861 64861\n",
      "ORD-CostCenter_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "Backup Duration: 0:00:00.844697\n",
      "\n",
      "\n",
      "Duration: 0:01:40.142906\n",
      "\n",
      "Total Execution Duration: 0:07:15.778901 \n",
      "-Import Completed-\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "con = None\n",
    "try:\n",
    "    \n",
    "    logging.basicConfig(filename = 'CommonConfigLog.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "    logging.info(f'\\nLOG START: {datetime.now()}\\n')\n",
    "    \n",
    "    def open_connection():\n",
    "        global server, database, driver, connection, con\n",
    "        with open(r'C:\\Users\\gmoye001\\configtest\\config.json', 'r') as fh:\n",
    "            config = json.load(fh)\n",
    "        server = config['server']\n",
    "        database = config['database']\n",
    "        driver = config['driver']\n",
    "        connection = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes'\n",
    "        con = pyodbc.connect(connection)\n",
    "        return con\n",
    "    \n",
    "    def connection_test():\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT @@version\")\n",
    "        row = cur.fetchone()\n",
    "        print(\"Connection established to: \",row[0])\n",
    "        cur.close()\n",
    "        con.commit()\n",
    "        logging.info(f\"\\nConnection established to: {row[0]}\\n\")\n",
    "        return print(f\"Connection established to: {row[0]}\")\n",
    "        \n",
    "    def close_connection():\n",
    "        con.close()\n",
    "        return\n",
    "    \n",
    "    def checktables(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_name = '%s'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n{tbl} does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_name = '%s_stage'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n{tbl}_stage does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "\n",
    "    \n",
    "    def checkbackups(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_name = '%s_backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n{tbl}_backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for {tbl} exists.', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for {tbl} exists.\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_name = '%s_stage-backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n{tbl}_stage-backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for {tbl}_stage exists.', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for {tbl}_stage exists.\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "    \n",
    "    def tablecontent(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [%s_stage]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        \n",
    "    def backup_data(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"INSERT INTO [%s_backup] SELECT * FROM [%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                duration = bend_time - bstart_time\n",
    "                logging.info(f'\\nBackup Duration: {duration}')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return\n",
    "        else:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"INSERT INTO [%s_stage-backup] SELECT * FROM [%s_stage]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                duration = bend_time - bstart_time\n",
    "                logging.info(f'\\nBackup Duration: {duration}')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return\n",
    "        \n",
    "    def create_backuptable(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [%s_backup] FROM [%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                duration = bend_time - bstart_time\n",
    "                logging.info(f'\\nBackup Duration: {duration}')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [%s_stage-backup] FROM [%s_stage]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                duration = bend_time - bstart_time\n",
    "                logging.info(f'\\nBackup Duration: {duration}')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    def backupcheck(con, tbl):\n",
    "        global rowcount\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [%s] UNION ALL SELECT COUNT(*) FROM [%s_backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [%s_stage] UNION ALL SELECT COUNT(*) FROM [%s_stage-backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "    \n",
    "    def truncate_table(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [%s]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n{tbl} has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n{tbl} has been succesfully truncated to import new data.\\n')\n",
    "                cur.close()\n",
    "                con.commit()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [%s_stage]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n{tbl}_stage has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n{tbl}_stage has been succesfully truncated to import new data.\\n')\n",
    "                cur.close()\n",
    "                con.commit()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "            \n",
    "    def truncate_backup(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [%s_backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n{tbl}_backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n{tbl}_backup has been succesfully truncated to create the next backup.\\n')\n",
    "                cur.close()\n",
    "                con.commit()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [%s_stage-backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n{tbl}_stage-backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n{tbl}_stage-backup has been succesfully truncated to create the next backup.\\n')\n",
    "                cur.close()\n",
    "                con.commit()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "\n",
    "    def importdata(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f\"mssql+pyodbc://{server}/{database}?driver={driver}?Trusted_Connection=yes\", fast_executemany = True)\n",
    "            pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}', engine, index = False, if_exists = 'append', schema = 'dbo')\n",
    "            return\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f\"mssql+pyodbc://{server}/{database}?driver={driver}?Trusted_Connection=yes\", fast_executemany = True)\n",
    "            pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}_stage', engine, index = False, if_exists = 'append', schema = 'dbo')\n",
    "            \n",
    "    def getData(CV):\n",
    "        # convert to config file/table\n",
    "        if stage == False:\n",
    "            url = f'https://api.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'C:\\Users\\gmoye001\\configtest\\apiconnect.json') as f:\n",
    "                headers = json.load(f)\n",
    "        else:\n",
    "            url = f'https://api-staging.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'C:\\Users\\gmoye001\\configtest\\apiconnectb.json') as f:\n",
    "                headers = json.load(f)\n",
    "    \n",
    "        \n",
    "        r = requests.get(url, headers=headers)\n",
    "        rjson = r.json()\n",
    "        keylist = ('URI','Categories','RelatedTerms')\n",
    "        \n",
    "        for key in keylist:\n",
    "            rjson = [{k: v for k, v in d.items() if k != key} for d in rjson]\n",
    "        \n",
    "        global df\n",
    "        df = pd.DataFrame(rjson)\n",
    "        datelist = ('CreatedDate','ModifiedDate','EffectiveDate', 'RelModifiedDate','ExpiryDate','Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime')\n",
    "        date_format = \"%Y%m%d%H%M%S\"\n",
    "        \n",
    "        for date in enumerate(datelist):\n",
    "            if date[1] in df:\n",
    "                df[date[1]] = df[date[1]].str.replace(\"\\.[0-9]*Z\", \"\").str.replace(\"Z\", \"\")\n",
    "                if date[1] != 'None':\n",
    "                    df[date[1]] = pd.to_datetime(df[date[1]], format=date_format, errors = 'coerce')\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        global recnum\n",
    "        recnum = len(df.index)\n",
    "        \n",
    "        #display(df)\n",
    "        #df.to_excel('output1.xlsx')\n",
    "        \n",
    "        if tablecontent(con, f'{CV}') == False:\n",
    "            importdata(con, f'{CV}')\n",
    "            print(f'\\n{CV} has been updated with {recnum} records')\n",
    "            logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "        else:\n",
    "            truncate_table(con, f'{CV}')\n",
    "            importdata(con, f'{CV}')\n",
    "            print(f'\\n{CV} has been updated with {recnum} records')\n",
    "            logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "            \n",
    "        #colnames = list(df)\n",
    "        \n",
    "        #display(colnames) \n",
    "         #[['Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime']])\n",
    "        \n",
    "        #--fetch column names for table creation and datatypes\n",
    "        #for colname, dt in itertools.product([df.columns],[df.dtypes]):\n",
    "            #print(dt)\n",
    "        #print('\\n')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open(r'C:\\Users\\gmoye001\\configtest\\CVsStage.csv', 'r') as cv_config:\n",
    "        CVsStage = cv_config.read().split(',')\n",
    "    with open(r'C:\\Users\\gmoye001\\configtest\\CVsProd.csv', 'r') as cv_config:\n",
    "        CVsProd = cv_config.read().split(',')\n",
    "\n",
    "    #Used for testing a group of CV's\n",
    "    CV = ['LEL-PwCLegalEntity-en','NS-PwCNetworkNode-en',\n",
    "           'NS-PwCNetworkNode-en-Territory',\n",
    "           'ORD-CostCenter']\n",
    "    #Used for testing a single CV\n",
    "    CVx = ['ORD-CostCenter']\n",
    "    \n",
    "    CVd = ['ORD-CostCenter']\n",
    "    \n",
    "    st = datetime.now()\n",
    "    open_connection()\n",
    "    connection_test()\n",
    "    close_connection()\n",
    "    \n",
    "    for urls in enumerate(CVsStage):\n",
    "        global stage\n",
    "        stage = True\n",
    "        open_connection()\n",
    "        #getData(urls[1])\n",
    "        #close_connection()\n",
    "        if checktables(con, urls[1]) == False:\n",
    "            print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "        else:\n",
    "            if checkbackups(con, urls[1]) == False:\n",
    "                create_backuptable(con, urls[1])\n",
    "                createdbackup = True\n",
    "            else:\n",
    "                createdbackup = False\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                getData(urls[1])\n",
    "                if createdbackup == False:\n",
    "                    backupcheck(con, urls[1])\n",
    "                else:\n",
    "                    pass\n",
    "                close_connection()\n",
    "                stage = False\n",
    "                gend_time = datetime.now()\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                print(\"\")\n",
    "            except (Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "        for i in range(10, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "\n",
    "    for urls in enumerate(CVsProd):\n",
    "        open_connection()\n",
    "        stage = False\n",
    "        #getData(urls[1])\n",
    "        #close_connection()\n",
    "        if checktables(con, urls[1]) == False:\n",
    "            print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "        else:\n",
    "            if checkbackups(con, urls[1]) == False:\n",
    "                create_backuptable(con, urls[1])\n",
    "                createdbackup = True\n",
    "            else:\n",
    "                createdbackup = False\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                getData(urls[1])\n",
    "                if createdbackup == False:\n",
    "                    backupcheck(con, urls[1])\n",
    "                else:\n",
    "                    pass\n",
    "                close_connection()\n",
    "                gend_time = datetime.now()\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                print(\"\")\n",
    "            except (Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "        for i in range(10, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "            \n",
    "    et = datetime.now()\n",
    "    print('Total Execution Duration: {}'.format(et - st),'\\n-Import Completed-')\n",
    "    tt = et - st\n",
    "    logging.info(f'\\nTotal Execution Duration: {tt}\\n')\n",
    "    logging.info('\\n-Import Completed-\\n')\n",
    "    \n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        logging.exception(\"message\")\n",
    "        pass\n",
    "    \n",
    "except r.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except r.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except r.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except r.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    logging.exception(\"message\")\n",
    "        \n",
    "finally:\n",
    "    logging.info(f'\\nLOG END: {datetime.now()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
