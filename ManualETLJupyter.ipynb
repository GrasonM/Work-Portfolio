{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9f56944b5b4c92a154078bff2a5489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select Stage CVs:', index=(0,), layout=Layout(height='auto', width='auto'), option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bebe5a92d4a4b2d8b4b7c424f5d932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Import Selected CVs', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504b33a99fe84cf1baaa2b12688c62aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select Prod CVs:', index=(0,), layout=Layout(height='auto', width='auto'), options…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b006dcbf9c4d8297772b046b04df4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Import Selected CVs', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GCV_API', 'GCV_PRD', 'ORD-CostCenterHierarchy_Normalised', 'BASE TABLE')]\n",
      "[GCV_PRD].ORD-CostCenterHierarchy_Normalised_backup does not exist in the database and will need to be created once parent table has data\n",
      "\n",
      "\n",
      "0 Existing records\n",
      "ORD-CostCenterHierarchy_Normalised has been updated with 91616 records\n",
      "\n",
      "Duration: 0:01:11.043310\n",
      "\n",
      "0 seconds until next table is imported \r"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import warnings, sys\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import ctypes\n",
    "import threading\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "global ImportActive, StageActive, ProdActive\n",
    "global stage, conn\n",
    "conn = False\n",
    "con = None\n",
    "try:\n",
    "    \n",
    "    global ImportActive, StageActive, ProdActive\n",
    "    logging.basicConfig(filename = 'CommonConfigManualLog.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "    logging.info(f'\\nLOG START: {datetime.now()}\\n')\n",
    "    \n",
    "    def open_connection():\n",
    "        global server, database, driver, dformat, connection, con\n",
    "        with open(r\"C:\\Users\\gmoye001\\config\\config.json\", 'r') as fh:\n",
    "            config = json.load(fh)\n",
    "        server = config['server']\n",
    "        database = config['database']\n",
    "        driver = config['driver']\n",
    "        dformat = config['dformat']\n",
    "        connection = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes'\n",
    "        con = pyodbc.connect(connection)\n",
    "        return con\n",
    "    \n",
    "    def connection_test():\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT @@version\")\n",
    "        row = cur.fetchone()\n",
    "        print(\"Connection established to: \",row[0])\n",
    "        cur.close()\n",
    "        con.commit()\n",
    "        logging.info(f\"\\nConnection established to: {row[0]}\\n\")\n",
    "        return \n",
    "        \n",
    "    def close_connection():\n",
    "        con.close()\n",
    "        conn = False\n",
    "        return\n",
    "    \n",
    "    def checktables(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_PRD' and table_name = '%s'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_PRD].{tbl} does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_STG' and table_name = '%s'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_STG].{tbl} does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "\n",
    "    \n",
    "    def checkbackups(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_PRD' and table_name = '%s_backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_PRD].{tbl}_backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for [GCV_PRD].{tbl} exists.', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for [GCV_PRD].{tbl} exists.\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_STG' and table_name = '%s_backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_STG].{tbl}_backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for [GCV_STG].{tbl}', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for [GCV_STG].{tbl}\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "    \n",
    "    def tablecontent(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_PRD].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_STG].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        \n",
    "    def backup_data(con, tbl):\n",
    "        if stage == False:\n",
    "            if is_identity(con, tbl) == True:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = f\"SET IDENTITY_INSERT [GCV_PRD].[%s_backup] ON; INSERT INTO [GCV_PRD].[%s_backup] ({fields}) SELECT {fields} FROM [GCV_PRD].[%s]; SET IDENTITY_INSERT [GCV_PRD].[%s_backup] OFF;\" % (tbl, tbl, tbl, tbl)\n",
    "                    print(f'\\n{query}\\n')\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            else:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = \"INSERT INTO [GCV_PRD].[%s_backup] SELECT * FROM [GCV_PRD].[%s]\" % (tbl, tbl)\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            return\n",
    "        else:\n",
    "            if is_identity(con, tbl) == True:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = f\"SET IDENTITY_INSERT [GCV_STG].[%s_backup] ON; INSERT INTO [GCV_STG].[%s_backup] ({fields}) SELECT {fields} FROM [GCV_STG].[%s]; SET IDENTITY_INSERT [GCV_STG].[%s_backup] OFF;\" % (tbl, tbl, tbl, tbl)\n",
    "                    print(f'\\n{query}\\n')\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            else:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = \"INSERT INTO [GCV_STG].[%s_backup] SELECT * FROM [GCV_STG].[%s]\" % (tbl, tbl)\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            return\n",
    "    \n",
    "    def get_fields(con, tbl):\n",
    "        global fields\n",
    "        if stage == False:\n",
    "            schema = 'GCV_PRD'\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '%s' AND TABLE_NAME = '%s'\" % (schema, tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                columns = cur.fetchall()\n",
    "                columns = columns[0:]\n",
    "                columns = list(zip(*columns))[0]\n",
    "                fields = \", \".join(map(str, columns))\n",
    "                print(f'\\n{fields}\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return fields\n",
    "        else:\n",
    "            schema = 'GCV_STG'\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '%s' AND TABLE_NAME = '%s'\" % (schema, tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                columns = cur.fetchall()\n",
    "                columns = columns[0:]\n",
    "                columns = list(zip(*columns))[0]\n",
    "                fields = \", \".join(map(str, columns))\n",
    "                print(f'\\n{fields}\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return fields\n",
    "        \n",
    "    def is_identity(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = '%s')\" % (tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                output = cur.fetchone()\n",
    "                if output is None:\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return False\n",
    "                else:\n",
    "                    output = output[0]\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return True\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return \n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = '%s')\" % (tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                output = cur.fetchone()\n",
    "                if output is None:\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return False\n",
    "                else:\n",
    "                    output = output[0]\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return True\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return\n",
    "        \n",
    "    def create_backuptable(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [GCV_PRD].[%s_backup] FROM [GCV_PRD].[%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl} backup table has been created.\\n')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [GCV_STG].[%s_backup] FROM [GCV_STG].[%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                logging.info(f'\\n[GCV_STG].{tbl} backup table has been created.\\n')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    def backupcheck(con, tbl):\n",
    "        global rowcount\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_PRD].[%s] UNION ALL SELECT COUNT(*) FROM [GCV_PRD].[%s_backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_STG].[%s] UNION ALL SELECT COUNT(*) FROM [GCV_STG].[%s_backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "    \n",
    "    def truncate_table(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_PRD].[%s]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_PRD].{tbl} has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl} has been succesfully truncated to import new data.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_STG].[%s]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_STG].{tbl} has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n[GCV_STG].{tbl} has been succesfully truncated to import new data.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "            \n",
    "    def truncate_backup(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_PRD].[%s_backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_PRD].{tbl}_backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl}_backup has been succesfully truncated to create the next backup.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_STG].[%s_backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_STG].{tbl}_backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n[GCV_STG].{tbl}_backup has been succesfully truncated to create the next backup.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "\n",
    "    def importdata(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f'mssql+pyodbc://{server}/{database}?driver={dformat}', fast_executemany = True)\n",
    "            #pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}', engine, index = False, if_exists = 'append', schema = 'GCV_PRD')\n",
    "            cur.close()\n",
    "            con.commit()\n",
    "            return\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f'mssql+pyodbc://{server}/{database}?driver={dformat}', fast_executemany = True)\n",
    "            #pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}', engine, index = False, if_exists = 'append', schema = 'GCV_STG')\n",
    "            cur.close()\n",
    "            con.commit()\n",
    "            return\n",
    "            \n",
    "    def getData(CV):\n",
    "        # convert to config file/table\n",
    "        if stage == False:\n",
    "            url = f'https://api.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'config\\apiconnect.json') as f:\n",
    "                headers = json.load(f)\n",
    "        else:\n",
    "            url = f'https://api-staging.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'config\\apiconnectb.json') as f:\n",
    "                headers = json.load(f)\n",
    "                \n",
    "        retry_strategy = Retry(total = 10, status_forcelist=[429, 413, 503], method_whitelist=[\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"])\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        http = requests.Session()\n",
    "        \n",
    "        http.mount(\"https://\", adapter)\n",
    "        r = http.get(url, headers=headers, timeout = 100)\n",
    "        rjson = r.json()\n",
    "        keylist = ('URI','Categories','RelatedTerms')\n",
    "        \n",
    "        if 'ErrorMessage' in rjson:\n",
    "            if rjson['ErrorMessage'] == 'CV does not exist in CVMaster List':\n",
    "                print('CV Currently Missing from CVMaster List')\n",
    "                return\n",
    "        else:\n",
    "            for key in keylist:\n",
    "                rjson = [{k: v for k, v in d.items() if k != key} for d in rjson]\n",
    "        \n",
    "            global df, recnum\n",
    "            df = pd.DataFrame(rjson)\n",
    "            datelist = ('CreatedDate','ModifiedDate','EffectiveDate', 'HierarchyNodeEffectiveDate', 'HierarchyNodeExpirationDate','RelModifiedDate','ExpiryDate','Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime')\n",
    "            date_format = \"%Y%m%d%H%M%S\"\n",
    "            \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore', FutureWarning)\n",
    "                for date in enumerate(datelist): \n",
    "                    if date[1] in df:\n",
    "                        \n",
    "                        if df[date[1]].iteritems() != 'None':\n",
    "                            if df[date[1]].str.contains('Z').items():\n",
    "                                df[date[1]] = df[date[1]].str.replace(\"\\.[0-9]*Z\", \"\").str.replace(\"Z\", \"\")\n",
    "                        if df[date[1]].iteritems() != 'None':   \n",
    "                            if df[date[1]].str.contains('-').items():\n",
    "                                df[date[1]] = df[date[1]].str.replace(\"\\W+\", \"\")\n",
    "                                \n",
    "                        df[date[1]] = df[date[1]].mask(df[date[1]].str.len() > 14, df[date[1]].str[:-3])\n",
    "                        df[date[1]] = pd.to_datetime(df[date[1]], format=date_format, errors = 'coerce')\n",
    "                        \n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "            recnum = len(df.index)\n",
    "            \n",
    "            #display(df)\n",
    "            #df.to_excel('output1.xlsx')\n",
    "            \n",
    "            if tablecontent(con, f'{CV}') == False:\n",
    "                importdata(con, f'{CV}')\n",
    "                print(f'\\n{CV} has been updated with {recnum} records')\n",
    "                logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "            else:\n",
    "                truncate_table(con, f'{CV}')\n",
    "                importdata(con, f'{CV}')\n",
    "                print(f'\\n{CV} has been updated with {recnum} records')\n",
    "                logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "                \n",
    "            #colnames = list(df)\n",
    "            \n",
    "            #display(colnames) \n",
    "             #[['Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime']])\n",
    "            \n",
    "            #--fetch column names for table creation and datatypes\n",
    "            #for colname, dt in itertools.product([df.columns],[df.dtypes]):\n",
    "                #print(dt)\n",
    "            #print('\\n')\n",
    "        \n",
    "            return df\n",
    "    \n",
    "    ListExtS = ['All', 'Exit', 'Prod']\n",
    "    ListExtP = ['All', 'Exit', 'Stage']\n",
    "    \n",
    "    def open_stage():\n",
    "        with open(r'config\\CVsStage.csv', 'r') as cv_config:\n",
    "            optionsstage = cv_config.read().split(',')\n",
    "        \n",
    "        global StageSelect, ExecuteButton1\n",
    "        \n",
    "        optionsstage.extend(ListExtS)\n",
    "        \n",
    "        StageSelect = widgets.SelectMultiple(\n",
    "        options = optionsstage,\n",
    "        value = [optionsstage[0]],\n",
    "        description='Select Stage CVs:',\n",
    "        style = {'description_width': 'initial'},\n",
    "        layout = Layout(width = 'auto', height = 'auto'),\n",
    "        )\n",
    "        \n",
    "        ExecuteButton1 = widgets.Button(description='Import Selected CVs')\n",
    "        output1 = widgets.Output()\n",
    "        \n",
    "        display(StageSelect, ExecuteButton1)\n",
    "    \n",
    "    def open_prod():\n",
    "        with open(r'config\\CVsProd.csv', 'r') as cv_config:\n",
    "            optionsprod = cv_config.read().split(',')\n",
    "            \n",
    "        global ProdSelect, ExecuteButton2\n",
    "        \n",
    "        optionsprod.extend(ListExtP)\n",
    "        \n",
    "        ProdSelect = widgets.SelectMultiple(\n",
    "        options = optionsprod,\n",
    "        value = [optionsprod[0]],\n",
    "        description='Select Prod CVs:',\n",
    "        style = {'description_width': 'initial'},\n",
    "        layout = Layout(width = 'auto', height = 'auto'),\n",
    "        )\n",
    "        \n",
    "        ExecuteButton2 = widgets.Button(description='Import Selected CVs')\n",
    "        output2 = widgets.Output()\n",
    "        \n",
    "        display(ProdSelect, ExecuteButton2)\n",
    "        \n",
    "        ProdSelect.layout.visibility = 'hidden'\n",
    "        ExecuteButton2.layout.visibility = 'hidden'\n",
    "    \n",
    "    st = datetime.now()\n",
    "    open_connection()\n",
    "    connection_test()\n",
    "    close_connection()\n",
    "    open_stage()\n",
    "    open_prod()\n",
    "    \n",
    "    def show_prod():\n",
    "        ProdSelect.layout.visibility = 'visible'\n",
    "        ExecuteButton2.layout.visibility = 'visible'\n",
    " \n",
    "    def show_stage():\n",
    "        StageSelect.layout.visibility = 'visible'\n",
    "        ExecuteButton1.layout.visibility = 'visible'\n",
    "    \n",
    "    def hide_prod():\n",
    "        ProdSelect.layout.visibility = 'hidden'\n",
    "        ExecuteButton2.layout.visibility = 'hidden'\n",
    " \n",
    "    def hide_stage():\n",
    "        StageSelect.layout.visibility = 'hidden'\n",
    "        ExecuteButton1.layout.visibility = 'hidden'\n",
    "    \n",
    "    def timedata():\n",
    "        et = datetime.now()\n",
    "        print('Total Execution Duration: {}'.format(et - st),'\\n-Import Completed-')\n",
    "        tt = et - st\n",
    "        logging.info(f'\\nTotal Execution Duration: {tt}\\n')\n",
    "        logging.info('\\n-Import Completed-\\n')\n",
    "            \n",
    "    def on_button1_clicked(b):\n",
    "        global stage, conn\n",
    "        hide_stage()\n",
    "        \n",
    "        CVsStage = list(StageSelect.value)\n",
    "        if (('All' in CVsStage) or ('Prod' in CVsStage) or ('Exit' in CVsStage)) and (len(CVsStage) > 1):\n",
    "            ctypes.windll.user32.MessageBoxW(0, \"You cannot select multiple options for 'All', 'Exit', or 'Prod'\", \"Error:\")\n",
    "            show_stage()\n",
    "        elif (CVsStage == ['All'] and len(CVsStage) == 1):\n",
    "            CVsStage = optionsstage[:-3]\n",
    "        elif (CVsStage == ['Exit']  and len(CVsStage) == 1):\n",
    "            StageSelect.close()\n",
    "            ExecuteButton1.close()\n",
    "            timedata()\n",
    "            os.system('cls')\n",
    "        elif (CVsStage == ['Prod']  and len(CVsStage) == 1):\n",
    "            show_prod()\n",
    "        else:\n",
    "            global stage, conn\n",
    "            for urls in enumerate(CVsStage):\n",
    "                stage = True\n",
    "                conn = True\n",
    "                open_connection()\n",
    "                #getData(urls[1])\n",
    "                #close_connection()\n",
    "                if checktables(con, urls[1]) == False:\n",
    "                    print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "                else:\n",
    "                    if checkbackups(con, urls[1]) == False:\n",
    "                        create_backuptable(con, urls[1])\n",
    "                        createdbackup = True\n",
    "                    else:\n",
    "                        createdbackup = False\n",
    "                    try:\n",
    "                        gstart_time = datetime.now()\n",
    "                        getData(urls[1])\n",
    "                        if createdbackup == False:\n",
    "                            backupcheck(con, urls[1])\n",
    "                        else:\n",
    "                            pass\n",
    "                        close_connection()\n",
    "                        stage = False\n",
    "                        conn = False\n",
    "                        gend_time = datetime.now()\n",
    "                        print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                        logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                        print(\"\")\n",
    "                    except (Exception, pyodbc.DatabaseError) as e:\n",
    "                        print(\"\")\n",
    "                        print(e)\n",
    "                        logging.exception('\\n')\n",
    "                        logging.exception(\"message\")\n",
    "                    for i in range(3, -1, -1):\n",
    "                            print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                            ti.sleep(1)\n",
    "                        \n",
    "                show_stage()\n",
    "    \n",
    "    ExecuteButton1.on_click(on_button1_clicked)\n",
    "                \n",
    "    def on_button2_clicked(b):\n",
    "        hide_prod()\n",
    "        global stage\n",
    "        CVsProd = list(ProdSelect.value)\n",
    "        if (('All' in CVsProd) or ('Prod' in CVsProd) or ('Exit' in CVsProd)) and (len(CVsProd) > 1):\n",
    "            ctypes.windll.user32.MessageBoxW(0, \"You cannot select multiple options for 'All', 'Exit', or 'Prod'\", \"Error:\")\n",
    "            show_prod()\n",
    "        elif (CVsProd == ['All'] and len(CVsProd) == 1):\n",
    "            CVsProd = optionsprod[:-3]\n",
    "        elif (CVsProd == ['Exit'] and len(CVsProd) == 1):\n",
    "            ProdSelect.close()\n",
    "            ExecuteButton2.close()\n",
    "            timedata()\n",
    "            os.system('cls')\n",
    "        elif (CVsProd == ['Stage'] and len(CVsProd) == 1):\n",
    "            show_stage()\n",
    "        else:\n",
    "            for urls in enumerate(CVsProd):\n",
    "                open_connection()\n",
    "                stage = False\n",
    "                conn = True\n",
    "                #getData(urls[1])\n",
    "                #close_connection()\n",
    "                if checktables(con, urls[1]) == False:\n",
    "                    print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "                else:\n",
    "                    if checkbackups(con, urls[1]) == False:\n",
    "                        create_backuptable(con, urls[1])\n",
    "                        createdbackup = True\n",
    "                    else:\n",
    "                        createdbackup = False\n",
    "                    try:\n",
    "                        gstart_time = datetime.now()\n",
    "                        getData(urls[1])\n",
    "                        if createdbackup == False:\n",
    "                            backupcheck(con, urls[1])\n",
    "                        else:\n",
    "                            pass\n",
    "                        close_connection()\n",
    "                        conn = False\n",
    "                        gend_time = datetime.now()\n",
    "                        print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                        logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                        print(\"\")\n",
    "                    except (Exception, pyodbc.DatabaseError) as e:\n",
    "                        print(\"\")\n",
    "                        print(e)\n",
    "                        logging.exception('\\n')\n",
    "                        logging.exception(\"message\")\n",
    "                    for i in range(3, -1, -1):\n",
    "                            print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                            ti.sleep(1)\n",
    "                        \n",
    "                show_prod()\n",
    "\n",
    "    ExecuteButton2.on_click(on_button2_clicked)\n",
    "    \n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        logging.exception(\"message\")\n",
    "        pass\n",
    "    \n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "        \n",
    "finally:\n",
    "    logging.info(f'\\nLOG END: {datetime.now()}\\n')\n",
    "    if conn == True:\n",
    "        close_connection()\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
