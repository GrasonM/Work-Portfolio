{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd==2.0.1\n",
      "  Using cached xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 1.2.0\n",
      "    Uninstalling xlrd-1.2.0:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\xlrd-1.2.0.dist-info\\\\INSTALLER'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Archive Directories Detected\n",
      ".ipynb_checkpoints\n",
      "Archive\n",
      "RepliconCSVConversion.log\n",
      "RepliconCSVPreprocessor-Copy1.ipynb\n",
      "RepliconCSVPreprocessor.py\n",
      "User List Report 2022-11-30 Da Vinci.xls\n",
      "\n",
      "User List Report 2022-11-30 Da Vinci.xls\n",
      "User List Report 2022-11-30 galaxy all.xls\n",
      "\n",
      "User List Report 2022-11-30 galaxy all.xls\n",
      "User List Report 2022-11-30 SG & NZ.xls\n",
      "\n",
      "User List Report 2022-11-30 SG & NZ.xls\n",
      "\n",
      "documents available for processing\n",
      "\n",
      "['User List Report 2022-11-30 Da Vinci.xls', 'User List Report 2022-11-30 galaxy all.xls', 'User List Report 2022-11-30 SG & NZ.xls']\n",
      "dict_keys(['Report']) \n",
      "\n",
      "\n",
      "1 sheets \n",
      "\n",
      "\n",
      "['Report'] \n",
      "\n",
      "\n",
      "User List Report 2022-11-30 Da Vinci.xls\n",
      "\n",
      "\n",
      "Duration: 0:00:02.574813\n",
      "dict_keys(['Report']) ocument is processedd\n",
      "\n",
      "\n",
      "1 sheets \n",
      "\n",
      "\n",
      "['Report'] \n",
      "\n",
      "\n",
      "User List Report 2022-11-30 galaxy all.xls\n",
      "\n",
      "\n",
      "Duration: 0:00:00.130284\n",
      "dict_keys(['Report']) ocument is processedd\n",
      "\n",
      "\n",
      "1 sheets \n",
      "\n",
      "\n",
      "['Report'] \n",
      "\n",
      "\n",
      "User List Report 2022-11-30 SG & NZ.xls\n",
      "\n",
      "\n",
      "Duration: 0:00:00.921026\n",
      "0 seconds until next document is processedd\r"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from glob import glob\n",
    "import shutil\n",
    "import requests\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import ctypes\n",
    "import threading\n",
    "import os\n",
    "\n",
    "global sheets\n",
    "#fp = f'{os.path.basename(os.getcwd())}'\n",
    "#filepath = fr'{fp}'\n",
    "filepath = fr'{os.getcwd()}'\n",
    "folderA = r'Archive'\n",
    "filepathA = os.path.join(filepath, folderA)\n",
    "folderB = r'xlsx'\n",
    "filepathB = os.path.join(filepathA, folderB)\n",
    "folderC = r'csv'\n",
    "filepathC = os.path.join(filepathA, folderC)\n",
    "\n",
    "try:\n",
    "    \n",
    "    logging.basicConfig(filename = 'RepliconCSVConversion.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "    logging.info(f'\\nLOG START: {datetime.now()}\\n')\n",
    "    \n",
    "    def check_folders():\n",
    "        if not os.path.exists(filepathA):\n",
    "            os.makedirs(filepathA)\n",
    "            print('Archives did not exist')\n",
    "        if not os.path.exists(filepathB):\n",
    "            os.makedirs(filepathB)\n",
    "            print('xlsx did not exist')\n",
    "        if not os.path.exists(filepathC):\n",
    "            os.makedirs(filepathC)\n",
    "            print('csv did not exist')\n",
    "        else:\n",
    "            print('Existing Archive Directories Detected')\n",
    "        return\n",
    "\n",
    "    def check_files():\n",
    "        global processlist\n",
    "        processlist = []\n",
    "        for file in os.listdir(filepath):\n",
    "            print(f'{file}')\n",
    "            if \"Da Vinci\" in file and file.endswith((\".xlsx\",\".xls\",\".xlsm\")):\n",
    "                print(f'\\n{file}')\n",
    "                processlist += [file]\n",
    "            if \"galaxy all\" in file and file.endswith((\".xlsx\",\".xls\",\".xlsm\")):\n",
    "                print(f'\\n{file}')\n",
    "                processlist += [file]\n",
    "            if \"SG & NZ\" in file and file.endswith((\".xlsx\",\".xls\",\".xlsm\")):\n",
    "                print(f'\\n{file}')\n",
    "                processlist += [file]\n",
    "        if processlist == []:\n",
    "            print('No Excel files were present')\n",
    "            processlist += ['None']\n",
    "        else:\n",
    "            pass\n",
    "        return processlist\n",
    "    \n",
    "    def convert_to_CSV(doc):\n",
    "        all_sheets = pd.read_excel(f'{filepath}'+'/'+f'{doc}', sheet_name=None)\n",
    "        sheets = all_sheets.keys()\n",
    "        docdir = doc.replace('.xlsx','').replace('.xls','').replace('.xlsm','')\n",
    "        filepathdoc = os.path.join(filepath, docdir)\n",
    "        print(sheets, '\\n\\n')\n",
    "        print(len(sheets), 'sheets' , '\\n\\n')\n",
    "        print(list(sheets), '\\n\\n')\n",
    "        print(doc)\n",
    "        \n",
    "        sheetlist = list(sheets)\n",
    "        if len(sheets) > 1:\n",
    "            if not os.path.exists(docdir):\n",
    "                os.makedirs(docdir)\n",
    "            for sheet_name in sheets:\n",
    "                sheet = pd.read_excel(f'{filepath}'+'/'+f'{doc}', sheet_name=sheet_name).to_csv(f'{filepathdoc}'+'/'+f'{docdir}' + '_' + f'{sheet_name}' + '.csv', encoding = 'utf-8', index = False)\n",
    "        else:\n",
    "            pd.read_excel(f'{filepath}'+'/'+f'{doc}', sheet_name=sheetlist[0]).to_csv(f'{filepath}'+'/'+f'{docdir}' + '.csv', encoding = 'utf-8', index = False)\n",
    "            #shutil.move(f'{filepath}'+'/'+f'{doc}', f'{filepathB}'+f'{doc}')\n",
    "    \n",
    "    def move_processed():\n",
    "        global processedlist\n",
    "        processedlist = []\n",
    "        for file in os.listdir(filepath):\n",
    "            print(f'{file}')\n",
    "            if file.startswith(\"DDRProcessed\") and file.endswith(\".csv\"):\n",
    "                print(f'\\n{file}')\n",
    "                processedlist += [file]\n",
    "            elif file.startswith((\"Archive\",\"Analysis\",\"Temp\")):\n",
    "                pass\n",
    "            elif ~file.startswith(\"DDRProcessed\"):\n",
    "                print('incorrect file name is present.')\n",
    "        if processedlist == []:\n",
    "            print('No files were present or did not have the correct naming scheme.')\n",
    "            processedlist += ['None']\n",
    "        else:\n",
    "            pass\n",
    "        return processedlist\n",
    "    \n",
    "    check_folders() \n",
    "    check_files()\n",
    "    if 'None' not in processlist:\n",
    "        print('\\ndocuments available for processing\\n')\n",
    "        print(processlist)\n",
    "        for doc in enumerate(processlist):\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                convert_to_CSV(doc[1])\n",
    "                gend_time = datetime.now()\n",
    "                print(\"\")\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "            except Exception as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "            for i in range(10, -1, -1):\n",
    "                    print(f\"{i} seconds until next document is processed\", end = \"\\r\")\n",
    "                    ti.sleep(1)\n",
    "    else:\n",
    "        print('documents not available for processing')\n",
    "        pass\n",
    "    \n",
    "    #if 'None' not in processedlist:\n",
    "    #    for file in processedlist:\n",
    "    #        shutil.move(f'{filepath}'+'/'+f'{processedlist[0]}', 'DataAndDuplicateReportAutomation/Archive/csv/'+f'{processedlist[0]}')\n",
    "    #        move_processed()\n",
    "    #    print('Processing Complete')\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        logging.exception(\"message\")\n",
    "        pass\n",
    "    \n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "        \n",
    "finally:\n",
    "    logging.info(f'\\nLOG END: {datetime.now()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
