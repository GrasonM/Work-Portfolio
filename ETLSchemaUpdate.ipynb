{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n",
      "[('GCV_API', 'GCV_STG', 'Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised', 'BASE TABLE')]\n",
      "Current backup for [GCV_STG].Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised\n",
      "6581 Existing records\n",
      "[GCV_STG].Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised has been succesfully truncated to import new data.\n",
      "\n",
      "Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised has been updated with 6581 records\n",
      "\n",
      "# of records in each table:  6581 6581\n",
      "[GCV_STG].Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_STG' AND TABLE_NAME = 'Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised'\n",
      "\n",
      "\n",
      "CostCenterPwCNetworkNodeId, CostCenterPwCNetworkDescriptor, CostCenterId, LocalCostCenterCode, CostCenterName, UniversalCostCenterCode, LegalEntityPartyId, LegalEntityName, ModifiedDate, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'Onboarding_ORD-CostCentreLegalEntity-en-GlobalHierarchy_Denormalised')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.256384\n",
      "\n",
      "\n",
      "Duration: 0:00:12.164387\n",
      "\n",
      "[('GCV_API', 'GCV_STG', 'ORD-CostCenter', 'BASE TABLE')]\n",
      "Current backup for [GCV_STG].ORD-CostCenter\n",
      "44205 Existing records\n",
      "[GCV_STG].ORD-CostCenter has been succesfully truncated to import new data.\n",
      "\n",
      "ORD-CostCenter has been updated with 44205 records\n",
      "\n",
      "# of records in each table:  44205 44205\n",
      "[GCV_STG].ORD-CostCenter_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_STG' AND TABLE_NAME = 'ORD-CostCenter'\n",
      "\n",
      "\n",
      "Local_Cost_Center_Code, Cost_Center_Name, Cost_Center_SK, Universal_Cost_Center_Code, Cost_Center_NK, Cost_Type_Descriptor, Cost_Type_UID, PwC_Network_Descriptor, PwC_Network_UID, OS_Global_Sub_LoS_Descriptor, Global_LoS_UID, OS_Function_Descriptor, Function_UID, EmployingFlag, Cost_Center_Status, Record_Status, Effective_Date, Expiration_Date, Comments, Ownership_Folder, Created_Datetime, Last_Modified_Datetime, Batch_Number, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'ORD-CostCenter')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.438541\n",
      "\n",
      "\n",
      "Duration: 0:00:50.956469\n",
      "\n",
      "[('GCV_API', 'GCV_STG', 'CES-Country-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_STG].CES-Country-en\n",
      "307 Existing records\n",
      "[GCV_STG].CES-Country-en has been succesfully truncated to import new data.\n",
      "\n",
      "CES-Country-en has been updated with 307 records\n",
      "\n",
      "# of records in each table:  307 307\n",
      "[GCV_STG].CES-Country-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_STG' AND TABLE_NAME = 'CES-Country-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, COUNTRY.KEY, WB.CODE, DB.NAME, WB.LONG.NAME, PRIMARY.CURRENCY, WB.SHORT.NAME, ISO.CODE, ISO.LONG.NAME, ISO.SHORT.NAME, TERRITORY.KEY, CPAlias, WB.COMMENTS, ALT.ISO.LONG.NAME, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'CES-Country-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.225817\n",
      "\n",
      "\n",
      "Duration: 0:00:15.470490\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-JobLevel-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-JobLevel-en exists.\n",
      "23 Existing records\n",
      "[GCV_PRD].NS-JobLevel-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-JobLevel-en has been updated with 23 records\n",
      "\n",
      "# of records in each table:  23 23\n",
      "[GCV_PRD].NS-JobLevel-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-JobLevel-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, JobLevelName, EffectiveDate, LastEditedReason, Systemofrecord, SortOrder, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-JobLevel-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.217011\n",
      "\n",
      "\n",
      "Duration: 0:00:06.445099\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'LEL-PwCLegalEntity-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].LEL-PwCLegalEntity-en exists.\n",
      "1535 Existing records\n",
      "[GCV_PRD].LEL-PwCLegalEntity-en has been succesfully truncated to import new data.\n",
      "\n",
      "LEL-PwCLegalEntity-en has been updated with 1535 records\n",
      "\n",
      "# of records in each table:  1535 1535\n",
      "[GCV_PRD].LEL-PwCLegalEntity-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'LEL-PwCLegalEntity-en'\n",
      "\n",
      "\n",
      "PartyReferenceId, PartyId, Name, ResponsibleNetworkNodeId, ResponsibleNetworkNode, OperatingNetworkNodeId, OperatingNetworkNode, EmployingNetworkNodeId, EmployingNetworkNode, DUNS, LELNumber, GFSId, RegisteredAddressLine1, RegisteredAddressLine2, RegisteredAddressLine3, RegisteredCity, RegisteredCountrySubdivisionId, RegisteredCountrySubdivisionCode, RegisteredCountrySubdivisionName, RegisteredCountryId, RegisteredCountryCode, RegisteredCountryName, RegisteredPostalCode, OperatingAddressLine1, OperatingAddressLine2, OperatingAddressLine3, OperatingCity, OperatingCountrySubdivisionId, OperatingCountrySubdivisionCode, OperatingCountrySubdivisionName, OperatingCountryId, OperatingCountryCode, OperatingCountryName, OperatingPostalCode, BillingAddressLine1, BillingAddressLine2, BillingAddressLine3, BillingCity, BillingCountrySubdivisionId, BillingCountrySubdivisionCode, BillingCountrySubdivisionName, BillingCountryId, BillingCountryCode, BillingCountryName, BillingPostalCode, EmployingLE, CreatedDate, PartyRoleId, PartyRole, ModifiedDate, LicenseTypeId, LicenseType, OrganisationTypeId, OrganisationType, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'LEL-PwCLegalEntity-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.248264\n",
      "\n",
      "\n",
      "Duration: 0:00:15.535075\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-ManagementLevel-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-ManagementLevel-en exists.\n",
      "11 Existing records\n",
      "[GCV_PRD].NS-ManagementLevel-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ManagementLevel-en has been updated with 11 records\n",
      "\n",
      "# of records in each table:  11 11\n",
      "[GCV_PRD].NS-ManagementLevel-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-ManagementLevel-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, ManagementLevelName, Abbreviation, Definition, EffectiveDate, LastEditedReason, Systemofrecord, SortOrder, GERCode, Comments, ExpiryDate, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-ManagementLevel-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.227558\n",
      "\n",
      "\n",
      "Duration: 0:00:05.709371\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-PwCNetworkNode-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-PwCNetworkNode-en exists.\n",
      "457 Existing records\n",
      "[GCV_PRD].NS-PwCNetworkNode-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-PwCNetworkNode-en has been updated with 457 records\n",
      "\n",
      "# of records in each table:  457 457\n",
      "[GCV_PRD].NS-PwCNetworkNode-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-PwCNetworkNode-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, NodeName, EffectiveDate, LastEditedReason, Systemofrecord, SourceMDMGERCode, SourceMDMSortPrefix, PRID, PartyID, NetworkNodeID, LocalAccountingCurrency, RegionalReportingCurrency, Disambiguator, Comments, GGCEPrefix, Definition, ExpiryDate, Abbreviation, SCMember, NLTMember, NodeTypeId, NodeType, TBDRateElementId, TBDRateElementName, TBDRateElementLevel, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-PwCNetworkNode-en')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.209413\n",
      "\n",
      "\n",
      "Duration: 0:00:23.290083\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-PwCNetworkNode-en-Territory', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-PwCNetworkNode-en-Territory exists.\n",
      "112 Existing records\n",
      "[GCV_PRD].NS-PwCNetworkNode-en-Territory has been succesfully truncated to import new data.\n",
      "\n",
      "NS-PwCNetworkNode-en-Territory has been updated with 112 records\n",
      "\n",
      "# of records in each table:  112 112\n",
      "[GCV_PRD].NS-PwCNetworkNode-en-Territory_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-PwCNetworkNode-en-Territory'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, NodeName, PRID, PartyID, NetworkNodeID, LocalAccountingCurrency, RegionalReportingCurrency, Definition, EffectiveDate, LastEditedReason, Systemofrecord, SourceMDMGERCode, SourceMDMSortPrefix, NodeTypeId, NodeType, Abbreviation, SCMember, GGCEPrefix, NLTMember, Disambiguator, Comments, TBDRateElementId, TBDRateElementName, TBDRateElementLevel, importTime, ExpiryDate\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-PwCNetworkNode-en-Territory')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.229303\n",
      "\n",
      "\n",
      "Duration: 0:00:10.305093\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-ResourceRole-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-ResourceRole-en exists.\n",
      "14 Existing records\n",
      "[GCV_PRD].NS-ResourceRole-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ResourceRole-en has been updated with 14 records\n",
      "\n",
      "# of records in each table:  14 14\n",
      "[GCV_PRD].NS-ResourceRole-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-ResourceRole-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, ResourceRoleName, Definition, EffectiveDate, LastEditedReason, Systemofrecord, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-ResourceRole-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.206303\n",
      "\n",
      "\n",
      "Duration: 0:00:05.112159\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-ResourceType-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-ResourceType-en exists.\n",
      "2 Existing records\n",
      "[GCV_PRD].NS-ResourceType-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-ResourceType-en has been updated with 2 records\n",
      "\n",
      "# of records in each table:  2 2\n",
      "[GCV_PRD].NS-ResourceType-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-ResourceType-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, BusinessObjectTypeName, Definition, EffectiveDate, LastEditedReason, Systemofrecord, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-ResourceType-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.213953\n",
      "\n",
      "\n",
      "Duration: 0:00:05.373653\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-WorkerType-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-WorkerType-en exists.\n",
      "2 Existing records\n",
      "[GCV_PRD].NS-WorkerType-en has been succesfully truncated to import new data.\n",
      "\n",
      "NS-WorkerType-en has been updated with 2 records\n",
      "\n",
      "# of records in each table:  2 2\n",
      "[GCV_PRD].NS-WorkerType-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-WorkerType-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, ApprovalStatus, CreatedDate, ModifiedDate, ResourceSubTypeName, Definition, EffectiveDate, LastEditedReason, Systemofrecord, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-WorkerType-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.238964\n",
      "\n",
      "\n",
      "Duration: 0:00:05.571769\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'NS-WorkerType-en_NS-ContractType-en_Normalised', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].NS-WorkerType-en_NS-ContractType-en_Normalised exists.\n",
      "12 Existing records\n",
      "[GCV_PRD].NS-WorkerType-en_NS-ContractType-en_Normalised has been succesfully truncated to import new data.\n",
      "\n",
      "NS-WorkerType-en_NS-ContractType-en_Normalised has been updated with 12 records\n",
      "\n",
      "# of records in each table:  12 12\n",
      "[GCV_PRD].NS-WorkerType-en_NS-ContractType-en_Normalised_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'NS-WorkerType-en_NS-ContractType-en_Normalised'\n",
      "\n",
      "\n",
      "Id, Descriptor, ParentId, RelModifiedDate, ResourceSubTypeName, Definition, EffectiveDate, ExpiryDate, LastEditedReason, Comments, Systemofrecord, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'NS-WorkerType-en_NS-ContractType-en_Normalised')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.241355\n",
      "\n",
      "\n",
      "Duration: 0:00:06.269104\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'ORD-CostCenter', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].ORD-CostCenter exists.\n",
      "66556 Existing records\n",
      "[GCV_PRD].ORD-CostCenter has been succesfully truncated to import new data.\n",
      "\n",
      "ORD-CostCenter has been updated with 66556 records\n",
      "\n",
      "# of records in each table:  66556 66556\n",
      "[GCV_PRD].ORD-CostCenter_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'ORD-CostCenter'\n",
      "\n",
      "\n",
      "Local_Cost_Center_Code, Cost_Center_Name, Cost_Center_SK, Universal_Cost_Center_Code, Cost_Center_NK, Cost_Type_Descriptor, Cost_Type_UID, PwC_Network_Descriptor, PwC_Network_UID, OS_Global_Sub_LoS_Descriptor, Global_LoS_UID, OS_Function_Descriptor, Function_UID, EmployingFlag, Cost_Center_Status, Active_Status, Effective_Date, Expiration_Date, Comments, Created_Datetime, Last_Modified_Datetime, Record_Status, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'ORD-CostCenter')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.914964\n",
      "\n",
      "\n",
      "Duration: 0:01:20.291287\n",
      "\n",
      "[('GCV_API', 'GCV_PRD', 'ORD-CostCenterHierarchy_Normalised', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].ORD-CostCenterHierarchy_Normalised exists.\n",
      "0 Existing records\n",
      "(pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515) (SQLExecute); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert the value NULL into column 'id', table 'GCV_API.GCV_PRD.ORD-CostCenterHierarchy_Normalised'; column does not allow nulls. INSERT fails. (515); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO [GCV_PRD].[ORD-CostCenterHierarchy_Normalised] ([NetworkNodeID], [NetworkNodeName], [NodeId], [NodeCode], [NodeName], [NodeUniversalCode], [HierarchyNodeID], [HierarchyNodeName], [HierarchyNodeRecordStatus], [HierarchyNodeEffectiveDate], [HierarchyNodeExpirationDate], [HierarchyId], [HierarchyName], [ParentNetworkNodeID], [ParentNetworkNodeName], [ParentNodeId], [ParentNodeCode], [ParentNodeName], [ParentNodeUniversalCode], [ActiveStatus], [CreatedDate], [ModifiedDate]) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: (('1974628', 'PwC India', '20056127', '4201214', 'Clients & Industries ADV|Dehradun', 'IN4201214', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056129', '4201221', 'Clients & Industries ADV|Ahmedabad', 'IN4201221', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056144', '4201311', 'Clients & Industries ASR|Gurugram', 'IN4201311', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056163', '4201381', 'Clients & Industries ASR|Kathmandu', 'IN4201381', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056178', '4201435', 'Clients & Industries TRS|Patna', 'IN4201435', '18609576', 'Local cost centre', 'deactivated', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'deactivated', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 4, 14, 5, 10, 48)), ('1974628', 'PwC India', '20056180', '4201442', 'Clients & Industries TRS|Chennai', 'IN4201442', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056193', '4201525', 'Clients & Industries ADV-Deals|Gandhinagar', 'IN4201525', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47)), ('1974628', 'PwC India', '20056227', '4201714', 'Clients & Industries ADV-MC|Dehradun', 'IN4201714', '18609576', 'Local cost centre', 'active', None, None, '18386249', 'Standard', '1974628', 'PwC India', '20001440', '42010', 'Clients & Industries', 'IN42010', 'active', datetime.datetime(2022, 3, 24, 6, 30, 47), datetime.datetime(2022, 3, 24, 6, 30, 47))  ... displaying 10 of 91616 total bound parameter sets ...  ('1974735', 'PwC France', '23999', 'FRX00C0101', 'Patrimoine Immobilier (SAAS)', 'FRFRX00C0101', '18609576', 'Local cost centre', 'deactivated', datetime.datetime(2019, 1, 18, 0, 0), datetime.datetime(2022, 6, 16, 0, 0), '18386249', 'Standard', '1974735', 'PwC France', '20001667', 'RY04', 'Occupancy & Purchasing', 'FRRY04', 'deactivated', datetime.datetime(2019, 1, 18, 19, 0, 46), datetime.datetime(2022, 6, 16, 11, 20, 46)), ('1974735', 'PwC France', '23414', 'FRZ0RF0302', 'OGC (IFS Est)', 'FRFRZ0RF0302', '18609576', 'Local cost centre', 'active', datetime.datetime(2019, 1, 18, 0, 0), None, '18386249', 'Standard', '1974735', 'PwC France', '20001701', 'RI28', 'OGC & R&Q', 'FRRI28', 'active', datetime.datetime(2019, 1, 18, 19, 0, 46), datetime.datetime(2022, 6, 16, 11, 20, 46)))]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GCV_API', 'GCV_PRD', 'CES-Country-en', 'BASE TABLE')]\n",
      "Current backup for [GCV_PRD].CES-Country-en exists.\n",
      "299 Existing records\n",
      "[GCV_PRD].CES-Country-en has been succesfully truncated to import new data.\n",
      "\n",
      "CES-Country-en has been updated with 299 records\n",
      "\n",
      "# of records in each table:  299 299\n",
      "[GCV_PRD].CES-Country-en_backup has been succesfully truncated to create the next backup.\n",
      "\n",
      "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'GCV_PRD' AND TABLE_NAME = 'CES-Country-en'\n",
      "\n",
      "\n",
      "Id, Name, VocabName, ActiveStatus, CreatedDate, ModifiedDate, COUNTRY.KEY, WB.CODE, DB.NAME, WB.LONG.NAME, PRIMARY.CURRENCY, WB.SHORT.NAME, ISO.CODE, ISO.LONG.NAME, ISO.SHORT.NAME, TERRITORY.KEY, WB.COMMENTS, ALT.ISO.LONG.NAME, importTime\n",
      "\n",
      "\n",
      "\n",
      "SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = 'CES-Country-en')\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Backup Duration: 0:00:00.219696\n",
      "\n",
      "\n",
      "Duration: 0:00:15.802165\n",
      "\n",
      "Total Execution Duration: 0:07:42.651949 \n",
      "-Import Completed-\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import warnings, sys\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import ctypes\n",
    "import threading\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "global stage, conn\n",
    "conn = False\n",
    "con = None\n",
    "try:\n",
    "    \n",
    "    global ImportActive, StageActive, ProdActive\n",
    "    logging.basicConfig(filename = 'CommonConfigManualLog.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "    logging.info(f'\\nLOG START: {datetime.now()}\\n')\n",
    "\n",
    "    def open_connection():\n",
    "        global server, database, driver, dformat, connection, con\n",
    "        with open(r\"config\\config.json\", 'r') as fh:\n",
    "            config = json.load(fh)\n",
    "        server = config['server']\n",
    "        database = config['database']\n",
    "        driver = config['driver']\n",
    "        dformat = config['dformat']\n",
    "        connection = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes'\n",
    "        con = pyodbc.connect(connection)\n",
    "        return con\n",
    "    \n",
    "    def connection_test():\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT @@version\")\n",
    "        row = cur.fetchone()\n",
    "        print(\"Connection established to: \",row[0])\n",
    "        cur.close()\n",
    "        con.commit()\n",
    "        logging.info(f\"\\nConnection established to: {row[0]}\\n\")\n",
    "        return \n",
    "        \n",
    "    def close_connection():\n",
    "        con.close()\n",
    "        conn = False\n",
    "        return\n",
    "    \n",
    "    def checktables(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_PRD' and table_name = '%s'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_PRD].{tbl} does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_STG' and table_name = '%s'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_STG].{tbl} does not exist in the database and will need to be created\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(output, end = \"\\r\")\n",
    "                cur.close()\n",
    "            return True\n",
    "\n",
    "    \n",
    "    def checkbackups(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_PRD' and table_name = '%s_backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_PRD].{tbl}_backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for [GCV_PRD].{tbl} exists.', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for [GCV_PRD].{tbl} exists.\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM information_schema.Tables WHERE table_schema = 'GCV_STG' and table_name = '%s_backup'\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchall()\n",
    "            if output == []:\n",
    "                output = f'\\n[GCV_STG].{tbl}_backup does not exist in the database and will need to be created once parent table has data\\n'\n",
    "                print(output, end = \"\\r\")\n",
    "                logging.info(output)\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\nCurrent backup for [GCV_STG].{tbl}', end = \"\\r\")\n",
    "                logging.info(f'\\nCurrent backup for [GCV_STG].{tbl}\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "    \n",
    "    def tablecontent(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_PRD].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_STG].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            #print(output)\n",
    "            if output[0] == 0:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return False\n",
    "            else:\n",
    "                print(f'\\n{output[0]} Existing records', end = \"\\r\")\n",
    "                logging.info(f'\\n{output[0]} Existing records\\n')\n",
    "                cur.close()\n",
    "                return True\n",
    "        \n",
    "    def backup_data(con, tbl):\n",
    "        if stage == False:\n",
    "            if is_identity(con, tbl) == True:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = f\"SET IDENTITY_INSERT [GCV_PRD].[%s_backup] ON; INSERT INTO [GCV_PRD].[%s_backup] ({fields}) SELECT {fields} FROM [GCV_PRD].[%s]; SET IDENTITY_INSERT [GCV_PRD].[%s_backup] OFF;\" % (tbl, tbl, tbl, tbl)\n",
    "                    print(f'\\n{query}\\n')\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            else:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = \"INSERT INTO [GCV_PRD].[%s_backup] SELECT * FROM [GCV_PRD].[%s]\" % (tbl, tbl)\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            return\n",
    "        else:\n",
    "            if is_identity(con, tbl) == True:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = f\"SET IDENTITY_INSERT [GCV_STG].[%s_backup] ON; INSERT INTO [GCV_STG].[%s_backup] ({fields}) SELECT {fields} FROM [GCV_STG].[%s]; SET IDENTITY_INSERT [GCV_STG].[%s_backup] OFF;\" % (tbl, tbl, tbl, tbl)\n",
    "                    print(f'\\n{query}\\n')\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            else:\n",
    "                try:\n",
    "                    bstart_time = datetime.now()\n",
    "                    cur = con.cursor()\n",
    "                    query = \"INSERT INTO [GCV_STG].[%s_backup] SELECT * FROM [GCV_STG].[%s]\" % (tbl, tbl)\n",
    "                    cur.execute(query)\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    bend_time = datetime.now()\n",
    "                    print('\\nBackup Duration: {}'.format(bend_time - bstart_time))\n",
    "                    duration = bend_time - bstart_time\n",
    "                    logging.info(f'\\nBackup Duration: {duration}')\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')   \n",
    "                except(Exception, pyodbc.DatabaseError) as e:\n",
    "                    print(\"\")\n",
    "                    logging.info('\\n')\n",
    "                    print(e)\n",
    "                    logging.exception(\"message\")\n",
    "                    cur.close()\n",
    "                    con.rollback()\n",
    "            return\n",
    "    \n",
    "    def get_fields(con, tbl):\n",
    "        global fields\n",
    "        if stage == False:\n",
    "            schema = 'GCV_PRD'\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '%s' AND TABLE_NAME = '%s'\" % (schema, tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                columns = cur.fetchall()\n",
    "                columns = columns[0:]\n",
    "                columns = list(zip(*columns))[0]\n",
    "                fields = \", \".join(map(str, columns))\n",
    "                print(f'\\n{fields}\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return fields\n",
    "        else:\n",
    "            schema = 'GCV_STG'\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '%s' AND TABLE_NAME = '%s'\" % (schema, tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                columns = cur.fetchall()\n",
    "                columns = columns[0:]\n",
    "                columns = list(zip(*columns))[0]\n",
    "                fields = \", \".join(map(str, columns))\n",
    "                print(f'\\n{fields}\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return fields\n",
    "        \n",
    "    def is_identity(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = f\"SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = '%s')\" % (tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                output = cur.fetchone()\n",
    "                if output is None:\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return False\n",
    "                else:\n",
    "                    output = output[0]\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return True\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return \n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT is_identity FROM sys.identity_columns WHERE object_id in ( SELECT id FROM sysobjects WHERE NAME = '%s')\" % (tbl)\n",
    "                print(f'\\n{query}\\n')\n",
    "                cur.execute(query)\n",
    "                output = cur.fetchone()\n",
    "                if output is None:\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return False\n",
    "                else:\n",
    "                    output = output[0]\n",
    "                    print(f'\\n{output}\\n')\n",
    "                    con.commit()\n",
    "                    cur.close()\n",
    "                    return True\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "            return\n",
    "        \n",
    "    def create_backuptable(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [GCV_PRD].[%s_backup] FROM [GCV_PRD].[%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl} backup table has been created.\\n')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                bstart_time = datetime.now()\n",
    "                cur = con.cursor()\n",
    "                query = \"SELECT * INTO [GCV_STG].[%s_backup] FROM [GCV_STG].[%s]\" % (tbl, tbl)\n",
    "                cur.execute(query)\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                bend_time = datetime.now()\n",
    "                logging.info(f'\\n[GCV_STG].{tbl} backup table has been created.\\n')\n",
    "                print(\"\")\n",
    "                logging.info('\\n')   \n",
    "            except(Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                logging.info('\\n')\n",
    "                print(e)\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    def backupcheck(con, tbl):\n",
    "        global rowcount\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_PRD].[%s] UNION ALL SELECT COUNT(*) FROM [GCV_PRD].[%s_backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT COUNT(*) FROM [GCV_STG].[%s] UNION ALL SELECT COUNT(*) FROM [GCV_STG].[%s_backup]\" % (tbl, tbl)\n",
    "            cur.execute(query)\n",
    "            output = cur.fetchone()\n",
    "            rowcount = []\n",
    "            while output is not None:\n",
    "                rowcount.append(output[0])\n",
    "                output = cur.fetchone()\n",
    "            print('\\n# of records in each table: ', rowcount[0], recnum, end = \"\\r\")\n",
    "            logging.info(f'\\n# of records in each table: {rowcount[0]}, {recnum}')\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            if recnum == rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif recnum < rowcount[0]:\n",
    "                truncate_backup(con, tbl)\n",
    "                get_fields(con, tbl)\n",
    "                backup_data(con, tbl)\n",
    "            elif rowcount[0] == 0:\n",
    "                pass\n",
    "            return rowcount\n",
    "    \n",
    "    def truncate_table(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_PRD].[%s]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_PRD].{tbl} has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl} has been succesfully truncated to import new data.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_STG].[%s]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_STG].{tbl} has been succesfully truncated to import new data.')\n",
    "                logging.info(f'\\n[GCV_STG].{tbl} has been succesfully truncated to import new data.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "            \n",
    "    def truncate_backup(con, tbl):\n",
    "        if stage == False:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_PRD].[%s_backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_PRD].{tbl}_backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n[GCV_PRD].{tbl}_backup has been succesfully truncated to create the next backup.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "        else:\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                query = \"TRUNCATE TABLE [GCV_STG].[%s_backup]\" % tbl\n",
    "                cur.execute(query)\n",
    "                print(f'\\n[GCV_STG].{tbl}_backup has been succesfully truncated to create the next backup.')\n",
    "                logging.info(f'\\n[GCV_STG].{tbl}_backup has been succesfully truncated to create the next backup.\\n')\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "            except Exception as err:\n",
    "                logging.exception(\"message\")\n",
    "                cur.close()\n",
    "                con.rollback()\n",
    "                #raise err\n",
    "\n",
    "    def importdata(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f'mssql+pyodbc://{server}/{database}?driver={dformat}', fast_executemany = True)\n",
    "            #pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}', engine, index = False, if_exists = 'append', schema = 'GCV_PRD')\n",
    "            cur.close()\n",
    "            con.commit()\n",
    "            return\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            engine = sa.create_engine(f'mssql+pyodbc://{server}/{database}?driver={dformat}', fast_executemany = True)\n",
    "            #pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "            df.to_sql(f'{tbl}', engine, index = False, if_exists = 'append', schema = 'GCV_STG')\n",
    "            cur.close()\n",
    "            con.commit()\n",
    "            return\n",
    "            \n",
    "    def getData(CV):\n",
    "        # convert to config file/table\n",
    "        if stage == False:\n",
    "            url = f'https://api.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'config\\apiconnect.json') as f:\n",
    "                headers = json.load(f)\n",
    "        else:\n",
    "            url = f'https://api-staging.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'config\\apiconnectb.json') as f:\n",
    "                headers = json.load(f)\n",
    "                \n",
    "        retry_strategy = Retry(total = 10, status_forcelist=[429, 413, 503], method_whitelist=[\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"])\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        http = requests.Session()\n",
    "        \n",
    "        http.mount(\"https://\", adapter)\n",
    "        r = http.get(url, headers=headers, timeout = 100)\n",
    "        rjson = r.json()\n",
    "        keylist = ('URI','Categories','RelatedTerms')\n",
    "        \n",
    "        if 'ErrorMessage' in rjson:\n",
    "            if rjson['ErrorMessage'] == 'CV does not exist in CVMaster List':\n",
    "                print('CV Currently Missing from CVMaster List')\n",
    "                return\n",
    "        else:\n",
    "            for key in keylist:\n",
    "                rjson = [{k: v for k, v in d.items() if k != key} for d in rjson]\n",
    "        \n",
    "            global df, recnum\n",
    "            df = pd.DataFrame(rjson)\n",
    "            datelist = ('CreatedDate','ModifiedDate','EffectiveDate', 'HierarchyNodeEffectiveDate', 'HierarchyNodeExpirationDate','RelModifiedDate','ExpiryDate','Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime')\n",
    "            date_format = \"%Y%m%d%H%M%S\"\n",
    "            \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore', FutureWarning)\n",
    "                for date in enumerate(datelist): \n",
    "                    if date[1] in df:\n",
    "                        \n",
    "                        if df[date[1]].iteritems() != 'None':\n",
    "                            if df[date[1]].str.contains('Z').items():\n",
    "                                df[date[1]] = df[date[1]].str.replace(\"\\.[0-9]*Z\", \"\").str.replace(\"Z\", \"\")\n",
    "                        if df[date[1]].iteritems() != 'None':   \n",
    "                            if df[date[1]].str.contains('-').items():\n",
    "                                df[date[1]] = df[date[1]].str.replace(\"\\W+\", \"\")\n",
    "                                \n",
    "                        df[date[1]] = df[date[1]].mask(df[date[1]].str.len() > 14, df[date[1]].str[:-3])\n",
    "                        df[date[1]] = pd.to_datetime(df[date[1]], format=date_format, errors = 'coerce')\n",
    "                        \n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "            recnum = len(df.index)\n",
    "            \n",
    "            #display(df)\n",
    "            #df.to_excel('output1.xlsx')\n",
    "            \n",
    "            if tablecontent(con, f'{CV}') == False:\n",
    "                importdata(con, f'{CV}')\n",
    "                print(f'\\n{CV} has been updated with {recnum} records')\n",
    "                logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "            else:\n",
    "                truncate_table(con, f'{CV}')\n",
    "                importdata(con, f'{CV}')\n",
    "                print(f'\\n{CV} has been updated with {recnum} records')\n",
    "                logging.info(f'\\n{CV} has been updated with {recnum} records\\n')\n",
    "                \n",
    "            #colnames = list(df)\n",
    "            \n",
    "            #display(colnames) \n",
    "             #[['Effective_Date','Expiration_Date','Created_Datetime','Last_Modified_Datetime']])\n",
    "            \n",
    "            #--fetch column names for table creation and datatypes\n",
    "            #for colname, dt in itertools.product([df.columns],[df.dtypes]):\n",
    "                #print(dt)\n",
    "            #print('\\n')\n",
    "        \n",
    "            return df\n",
    "    \n",
    "    \n",
    "    #Fetches list of names for both prod and stage import\n",
    "    with open(r'C:\\Users\\gmoye001\\config\\CVsStage.csv', 'r') as cv_config:\n",
    "        CVsStage = cv_config.read().split(',')\n",
    "    with open(r'C:\\Users\\gmoye001\\config\\CVsProd.csv', 'r') as cv_config:\n",
    "        CVsProd = cv_config.read().split(',')\n",
    "\n",
    "    #Used for testing a group of CV's\n",
    "    CV = ['LEL-PwCLegalEntity-en','NS-PwCNetworkNode-en',\n",
    "           'NS-PwCNetworkNode-en-Territory',\n",
    "           'ORD-CostCenter']\n",
    "    #Used for testing a single CV\n",
    "    CVx = ['ORD-CostCenter']\n",
    "    \n",
    "    CVd = ['ORD-CostCenter']\n",
    "    \n",
    "    #Upon Initial execution, this is the first process that takes place to test connectivity between you and the server\n",
    "    st = datetime.now()\n",
    "    open_connection()\n",
    "    connection_test()\n",
    "    close_connection()\n",
    "    \n",
    "    #Staging process\n",
    "    for urls in enumerate(CVsStage):\n",
    "        global stage, conn\n",
    "        stage = True\n",
    "        conn = True\n",
    "        open_connection()\n",
    "        #getData(urls[1])\n",
    "        #close_connection()\n",
    "        if checktables(con, urls[1]) == False:\n",
    "            print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "        else:\n",
    "            if checkbackups(con, urls[1]) == False:\n",
    "                create_backuptable(con, urls[1])\n",
    "                createdbackup = True\n",
    "            else:\n",
    "                createdbackup = False\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                getData(urls[1])\n",
    "                if createdbackup == False:\n",
    "                    backupcheck(con, urls[1])\n",
    "                else:\n",
    "                    pass\n",
    "                close_connection()\n",
    "                stage = False\n",
    "                conn = False\n",
    "                gend_time = datetime.now()\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                print(\"\")\n",
    "            except (Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "        for i in range(10, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Production process\n",
    "    for urls in enumerate(CVsProd):\n",
    "        open_connection()\n",
    "        stage = False\n",
    "        conn = True\n",
    "        #getData(urls[1])\n",
    "        #close_connection()\n",
    "        if checktables(con, urls[1]) == False:\n",
    "            print(\"Moving to next table.\\n\", end = \"\\r\")\n",
    "        else:\n",
    "            if checkbackups(con, urls[1]) == False:\n",
    "                create_backuptable(con, urls[1])\n",
    "                createdbackup = True\n",
    "            else:\n",
    "                createdbackup = False\n",
    "            try:\n",
    "                gstart_time = datetime.now()\n",
    "                getData(urls[1])\n",
    "                if createdbackup == False:\n",
    "                    backupcheck(con, urls[1])\n",
    "                else:\n",
    "                    pass\n",
    "                close_connection()\n",
    "                conn = False\n",
    "                gend_time = datetime.now()\n",
    "                print('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                logging.info('\\nDuration: {}'.format(gend_time - gstart_time))\n",
    "                print(\"\")\n",
    "            except (Exception, pyodbc.DatabaseError) as e:\n",
    "                print(\"\")\n",
    "                print(e)\n",
    "                logging.exception('\\n')\n",
    "                logging.exception(\"message\")\n",
    "        for i in range(10, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "            \n",
    "    et = datetime.now()\n",
    "    print('Total Execution Duration: {}'.format(et - st),'\\n-Import Completed-')\n",
    "    tt = et - st\n",
    "    logging.info(f'\\nTotal Execution Duration: {tt}\\n')\n",
    "    logging.info('\\n-Import Completed-\\n')\n",
    "    \n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        logging.exception(\"message\")\n",
    "        pass\n",
    "    \n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "    \n",
    "except requests.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    conn = False\n",
    "    logging.exception(\"message\")\n",
    "        \n",
    "finally:\n",
    "    logging.info(f'\\nLOG END: {datetime.now()}\\n')\n",
    "    if conn == True:\n",
    "        close_connection()\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n",
      "['CostCenterPwCNetworkNodeId', 'CostCenterPwCNetworkDescriptor', 'CostCenterId', 'LocalCostCenterCode', 'CostCenterName', 'UniversalCostCenterCode', 'LegalEntityPartyId', 'LegalEntityName', 'ModifiedDate'] \n",
      "\n",
      "['CostCenterPwCNetworkNodeId', 'CostCenterPwCNetworkDescriptor', 'CostCenterId', 'LocalCostCenterCode', 'CostCenterName', 'UniversalCostCenterCode', 'LegalEntityPartyId', 'LegalEntityName', 'ModifiedDate'] \n",
      "\n",
      "['Local_Cost_Center_Code', 'Cost_Center_Name', 'Cost_Center_SK', 'Universal_Cost_Center_Code', 'Cost_Center_NK', 'Cost_Type_Descriptor', 'Cost_Type_UID', 'PwC_Network_Descriptor', 'PwC_Network_UID', 'OS_Global_Sub_LoS_Descriptor', 'Global_LoS_UID', 'OS_Function_Descriptor', 'Function_UID', 'Employing_Flag', 'Cost_Center_Status', 'Active_Status', 'Effective_Date', 'Expiration_Date', 'Comments', 'Ownership_Folder', 'Created_Datetime', 'Last_Modified_Datetime', 'Batch_Number'] \n",
      "\n",
      "['Local_Cost_Center_Code', 'Cost_Center_Name', 'Cost_Center_SK', 'Universal_Cost_Center_Code', 'Cost_Center_NK', 'Cost_Type_Descriptor', 'Cost_Type_UID', 'PwC_Network_Descriptor', 'PwC_Network_UID', 'OS_Global_Sub_LoS_Descriptor', 'Global_LoS_UID', 'OS_Function_Descriptor', 'Function_UID', 'Employing_Flag', 'Cost_Center_Status', 'Active_Status', 'Effective_Date', 'Expiration_Date', 'Comments', 'Ownership_Folder', 'Created_Datetime', 'Last_Modified_Datetime', 'Batch_Number'] \n",
      "\n",
      "['Id', 'Name', 'VocabName', 'ActiveStatus', 'CreatedDate', 'ModifiedDate', 'JobLevelName', 'EffectiveDate', 'LastEditedReason', 'Systemofrecord', 'SortOrder'] \n",
      "\n",
      "['Id', 'Name', 'VocabName', 'ActiveStatus', 'ApprovalStatus', 'CreatedDate', 'ModifiedDate', 'JobLevelName', 'EffectiveDate', 'LastEditedReason', 'Systemofrecord', 'SortOrder'] \n",
      "\n",
      "['PartyReferenceId', 'PartyId', 'Name', 'ResponsibleNetworkNodeId', 'ResponsibleNetworkNode', 'OperatingNetworkNodeId', 'OperatingNetworkNode', 'EmployingNetworkNodeId', 'EmployingNetworkNode', 'DUNS', 'LELNumber', 'GFSId', 'RegisteredAddressLine1', 'RegisteredAddressLine2', 'RegisteredAddressLine3', 'RegisteredCity', 'RegisteredCountrySubdivisionId', 'RegisteredCountrySubdivisionCode', 'RegisteredCountrySubdivisionName', 'RegisteredCountryId', 'RegisteredCountryCode', 'RegisteredCountryName', 'RegisteredPostalCode', 'OperatingAddressLine1', 'OperatingAddressLine2', 'OperatingAddressLine3', 'OperatingCity', 'OperatingCountrySubdivisionId', 'OperatingCountrySubdivisionCode', 'OperatingCountrySubdivisionName', 'OperatingCountryId', 'OperatingCountryCode', 'OperatingCountryName', 'OperatingPostalCode', 'BillingAddressLine1', 'BillingAddressLine2', 'BillingAddressLine3', 'BillingCity', 'BillingCountrySubdivisionId', 'BillingCountrySubdivisionCode', 'BillingCountrySubdivisionName', 'BillingCountryId', 'BillingCountryCode', 'BillingCountryName', 'BillingPostalCode', 'EmployingLE', 'CreatedDate', 'PartyRoleId', 'PartyRole', 'ModifiedDate', 'LicenseTypeId', 'LicenseType', 'OrganisationTypeId', 'OrganisationType'] \n",
      "\n",
      "['PartyReferenceId', 'PartyId', 'Name', 'ResponsibleNetworkNodeId', 'ResponsibleNetworkNode', 'OperatingNetworkNodeId', 'OperatingNetworkNode', 'EmployingNetworkNodeId', 'EmployingNetworkNode', 'DUNS', 'LELNumber', 'GFSId', 'RegisteredAddressLine1', 'RegisteredAddressLine2', 'RegisteredAddressLine3', 'RegisteredCity', 'RegisteredCountrySubdivisionId', 'RegisteredCountrySubdivisionCode', 'RegisteredCountrySubdivisionName', 'RegisteredCountryId', 'RegisteredCountryCode', 'RegisteredCountryName', 'RegisteredPostalCode', 'OperatingAddressLine1', 'OperatingAddressLine2', 'OperatingAddressLine3', 'OperatingCity', 'OperatingCountrySubdivisionId', 'OperatingCountrySubdivisionCode', 'OperatingCountrySubdivisionName', 'OperatingCountryId', 'OperatingCountryCode', 'OperatingCountryName', 'OperatingPostalCode', 'BillingAddressLine1', 'BillingAddressLine2', 'BillingAddressLine3', 'BillingCity', 'BillingCountrySubdivisionId', 'BillingCountrySubdivisionCode', 'BillingCountrySubdivisionName', 'BillingCountryId', 'BillingCountryCode', 'BillingCountryName', 'BillingPostalCode', 'EmployingLE', 'CreatedDate', 'PartyRoleId', 'PartyRole', 'ModifiedDate', 'LicenseTypeId', 'LicenseType', 'OrganisationTypeId', 'OrganisationType'] \n",
      "\n",
      "['Id', 'Name', 'VocabName', 'ActiveStatus', 'CreatedDate', 'ModifiedDate', 'ManagementLevelName', 'Abbreviation', 'Definition', 'EffectiveDate', 'LastEditedReason', 'Systemofrecord', 'SortOrder', 'GERCode', 'Comments', 'ExpiryDate'] \n",
      "\n",
      "['Id', 'Name', 'VocabName', 'ActiveStatus', 'ApprovalStatus', 'CreatedDate', 'ModifiedDate', 'ManagementLevelName', 'Abbreviation', 'Definition', 'EffectiveDate', 'LastEditedReason', 'Systemofrecord', 'SortOrder', 'GERCode', 'Comments', 'ExpiryDate'] \n",
      "\n",
      "0 seconds until next table is imported \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-af10fdde9d94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i} seconds until next table is imported \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Pseudocode for automated field creation/deletion\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "global df, df2\n",
    "con = None\n",
    "try:\n",
    "    \n",
    "    def open_connection():\n",
    "        global server, database, driver, connection, con\n",
    "        with open(r'C:\\Users\\gmoye001\\config\\config.json', 'r') as fh:\n",
    "            config = json.load(fh)\n",
    "        server = config['server']\n",
    "        database = config['database']\n",
    "        driver = config['driver']\n",
    "        connection = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes'\n",
    "        con = pyodbc.connect(connection)\n",
    "        return con\n",
    "    \n",
    "    def connection_test():\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT @@version\")\n",
    "        row = cur.fetchone()\n",
    "        print(\"Connection established to: \",row[0])\n",
    "        cur.close()\n",
    "        con.commit()\n",
    "        return \n",
    "        \n",
    "    def close_connection():\n",
    "        con.close()\n",
    "        return\n",
    "    \n",
    "    def fetch_dbtbl_column_names(con, tbl):\n",
    "        if stage == False:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM [GCV_PRD].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            dbcols = [column[0] for column in cur.description]\n",
    "            cur.close()\n",
    "            return dbcols\n",
    "        else:\n",
    "            cur = con.cursor()\n",
    "            query = \"SELECT * FROM [GCV_STG].[%s]\" % tbl\n",
    "            cur.execute(query)\n",
    "            dbcols = [column[0] for column in cur.description]\n",
    "            cur.close()\n",
    "            return dbcols\n",
    "        \n",
    "    #def create_field():\n",
    "    #    global df, df2\n",
    "    #    for field in enumerate(apifields):\n",
    "    #        if field[1] not in dbtblfields:\n",
    "    #            print('creating db table field')\n",
    "    #            \n",
    "    #            if df[f'{field[1]}'].dtype == 'int64':\n",
    "    #                datatype = 'BigInt'\n",
    "    #            if df[f'{field[1]}'].dtype == 'object':\n",
    "    #                print(max(df.loc[:,field[1]].apply(len)))\n",
    "    #                if max(df.loc[:,field[1]].apply(len)) < 255:\n",
    "    #                    datatype = 'nvarchar(510)'\n",
    "    #                elif max(df.loc[:, field[1]].apply(len)) > 255:\n",
    "    #                    datatype = 'varchar(MAX)'\n",
    "    #            if 'Date' in field[1]:\n",
    "    #                datatype = 'datetime'  \n",
    "    #            else:\n",
    "    #                datatype = df[f'{field[1]}'].dtype\n",
    "    #            print('datatype is', df[f'{field[1]}'].dtype, ', Post Analysis datatype is', datatype,', fieldname is', field[1])\n",
    "    #            df2 = pd.concat([df2, df[f'{field[1]}']], axis =1)\n",
    "    #    return print('Field Creation Complete')\n",
    "\n",
    "    #    \n",
    "    #def delete_field():\n",
    "    #    global df, df2\n",
    "    #    for field in enumerate(dbtblfields):\n",
    "    #        if field[1] not in apifields:\n",
    "    #            print('deleting db table field')\n",
    "    #            print('datatype is', df2[f'{field[1]}'].dtype, ', fieldname is', field[1])\n",
    "    #            del df2[f'{field[1]}']\n",
    "    #    return print('Field Deletion Complete')\n",
    "    #\n",
    "    #print(len(apifields), 'fields in the api table')\n",
    "    #print(len(dbtblfields[:-1]), 'fields in the database table')\n",
    "    #\n",
    "    #if len(apifields) > len(dbtblfields[:-1]):\n",
    "    #    create_field()\n",
    "    #    df2.insert(len(df2)+1, 'importTime', df2.pop('importTime'))\n",
    "    #    display(df, df2)\n",
    "    #if len(apifields) < len(dbtblfields[:-1]):\n",
    "    #    delete_field()\n",
    "    #    display(df, df2)\n",
    "    \n",
    "    with open(r'C:\\Users\\gmoye001\\config\\CVsStage.csv', 'r') as cv_config:\n",
    "        CVsStage = cv_config.read().split(',')\n",
    "    with open(r'C:\\Users\\gmoye001\\config\\CVsProd.csv', 'r') as cv_config:\n",
    "        CVsProd = cv_config.read().split(',')\n",
    "\n",
    "    def getData(CV):\n",
    "        \n",
    "        if stage == False:\n",
    "            url = f'https://api.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'C:\\Users\\gmoye001\\config\\apiconnect.json') as f:\n",
    "                headers = json.load(f)\n",
    "        else:\n",
    "            url = f'https://api-staging.pwcinternal.com:7443/GlobalCVService/GlobalCVService.svc/cv/{CV}'\n",
    "            with open(r'C:\\Users\\gmoye001\\config\\apiconnectb.json') as f:\n",
    "                headers = json.load(f)\n",
    "    \n",
    "        \n",
    "        r = requests.get(url, headers=headers)\n",
    "        rjson = r.json()\n",
    "        keylist = ('URI','Categories','RelatedTerms')\n",
    "        \n",
    "        for key in keylist:\n",
    "            rjson = [{k: v for k, v in d.items() if k != key} for d in rjson]\n",
    "        \n",
    "        global df\n",
    "        df = pd.DataFrame(rjson)\n",
    "        \n",
    "        apifields = list(df.columns)\n",
    "        #fetch_dbtbl_column_names(con, f'{CV}')\n",
    "        \n",
    "        print(apifields, '\\n')\n",
    "        dbcols = fetch_dbtbl_column_names(con, f'{CV}')\n",
    "        print(dbcols[:-1], '\\n')\n",
    "        \n",
    "    open_connection()\n",
    "    connection_test()\n",
    "    close_connection()\n",
    "    \n",
    "    for urls in enumerate(CVsStage):\n",
    "        global stage, conn\n",
    "        open_connection()\n",
    "        stage = True\n",
    "        conn = True\n",
    "        getData(urls[1])\n",
    "        close_connection()\n",
    "        conn = False\n",
    "        for i in range(2, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "\n",
    "    for urls in enumerate(CVsProd):\n",
    "        open_connection()\n",
    "        stage = False\n",
    "        conn = True\n",
    "        getData(urls[1])\n",
    "        close_connection()\n",
    "        conn = False\n",
    "        for i in range(2, -1, -1):\n",
    "                print(f\"{i} seconds until next table is imported \", end = \"\\r\")\n",
    "                ti.sleep(1)\n",
    "    \n",
    "\n",
    "\n",
    "#def create_field(con, tbl):\n",
    "#    for fields in enumerate(apifields):\n",
    "#        if stage == False:\n",
    "#            if fields[1] not in dbtblfields\n",
    "#                cur = con.cursor()\n",
    "#                query = f\"ALTER TABLE [GCV_PRD].[%s] ADD {fields[1]} ;\" % tbl\n",
    "#                cur.execute(query)\n",
    "#                output = cur.fetchall()\n",
    "#                cur.close()\n",
    "#                print(output, end = \"\\r\")\n",
    "#                logging.info(output, end = \"\\r\")\n",
    "#\n",
    "#        else:\n",
    "#            if fields[1] not in dbtblfields\n",
    "#                cur = con.cursor()\n",
    "#                query = f\"ALTER TABLE [GCV_STG].[%s] ADD {fields[1]} ;\" % tbl\n",
    "#                cur.execute(query)\n",
    "#                output = cur.fetchall()\n",
    "#                cur.close()\n",
    "#                print(output, end = \"\\r\")\n",
    "#                logging.info(output, end = \"\\r\")\n",
    "#        return\n",
    "#    \n",
    "#def delete_field(con, tbl):\n",
    "#    for fields in enumerate(apifields):\n",
    "#        if stage == False:\n",
    "#            if fields[1] not in apifields\n",
    "#                cur = con.cursor()\n",
    "#                query = f\"ALTER TABLE [GCV_PRD].[%s] DROP COLUMN {fields[1]};\" % tbl\n",
    "#                cur.execute(query)\n",
    "#                output = cur.fetchall()\n",
    "#                cur.close()\n",
    "#                print(output, end = \"\\r\")\n",
    "#                logging.info(output, end = \"\\r\")\n",
    "#        else:\n",
    "#            if fields[1] not in dbtblfields\n",
    "#                cur = con.cursor()\n",
    "#                query = f\"ALTER TABLE [GCV_STG].[%s] DROP COLUMN {fields[1]};\" % tbl\n",
    "#                cur.execute(query)\n",
    "#                output = cur.fetchall()\n",
    "#                cur.close()\n",
    "#                print(output, end = \"\\r\")\n",
    "#                logging.info(output, end = \"\\r\")\n",
    "#        return\n",
    "\n",
    "#exceptions \n",
    "except (Exception, pyodbc.DatabaseError) as error:\n",
    "        print(error)\n",
    "        pass\n",
    "    \n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(\"Http Error:\",  errh)\n",
    "    con = False\n",
    "    \n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(\"Error Connecting:\", errc)\n",
    "    con = False\n",
    "    \n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(\"Timeout Error:\", errt)\n",
    "    con = False\n",
    "    \n",
    "except requests.exceptions.RequestException as erru:\n",
    "    print(\"Unidentified Request Exception:\", erru)\n",
    "    con = False\n",
    "        \n",
    "finally:\n",
    "    if conn == True:\n",
    "        close_connection()\n",
    "    if cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import itertools\n",
    "from requests.exceptions import ConnectionError, HTTPError, Timeout, TooManyRedirects\n",
    "import traceback\n",
    "import logging\n",
    "import logging.handlers\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, event\n",
    "import json\n",
    "import time as ti\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "    #Opens connection to the SQL Server via the stored config file in the config folder\n",
    "def open_connection():\n",
    "    global server, database, driver, connection, con\n",
    "    with open(r'C:\\Users\\gmoye001\\config\\config.json', 'r') as fh:\n",
    "        config = json.load(fh)\n",
    "    server = config['server']\n",
    "    database = config['database']\n",
    "    driver = config['driver']\n",
    "    connection = f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes'\n",
    "    con = pyodbc.connect(connection)\n",
    "    return con\n",
    "\n",
    "#Tests the connction to the sql server by executing a query that returns the information of the server\n",
    "def connection_test():\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SELECT @@version\")\n",
    "    row = cur.fetchone()\n",
    "    print(\"Connection established to: \",row[0])\n",
    "    cur.close()\n",
    "    con.commit()\n",
    "    logging.info(f\"\\nConnection established to: {row[0]}\\n\")\n",
    "    return \n",
    "\n",
    "#simply closes the connection to the server    \n",
    "def close_connection():\n",
    "    con.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Connection at 0x1b77f90c2a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) \n",
      "\tMar 18 2018 09:11:49 \n",
      "\tCopyright (c) Microsoft Corporation\n",
      "\tEnterprise Edition (64-bit) on Windows Server 2016 Datacenter 10.0 <X64> (Build 14393: ) (Hypervisor)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connection_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
